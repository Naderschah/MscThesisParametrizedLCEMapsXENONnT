{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing RAW Data\n",
    "\n",
    "See notes in retrieve_data\n",
    "\n",
    "Next set in mnt_point2 \n",
    "\n",
    "Also start copying into /scratch/midway2/fsemler/out_dat using the admix_env.sh again\n",
    "\n",
    "When its done rsync into mnt_point making sure everything else is cleared\n",
    "\n",
    "Also update text in retrieve_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, json\n",
    "sys.path.append('/Code/')\n",
    "os.environ['XENON_CONFIG'] = '/Code/xenon.config'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 14:40:36,300 - admix - WARNING - Initializing utilix DB failed. You cannot do database operations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB initialization failed\n"
     ]
    }
   ],
   "source": [
    "import straxen\n",
    "import cutax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dir  = \"/Code/mnt_point2\"\n",
    "out_dir = \"/Code/strax_data2\"\n",
    "\n",
    "max_workers = 25\n",
    "\n",
    "# Set up strax context\n",
    "_database_init = False\n",
    "we_are_the_daq = False\n",
    "output_folder = out_dir\n",
    "include_rucio_remote = False\n",
    "include_online_monitor = False\n",
    "include_rucio_local = False\n",
    "download_heavy = False\n",
    "_auto_append_rucio_local = False\n",
    "# Idk which of those is the correct one but it works\n",
    "_rucio_path = in_dir\n",
    "_rucio_local_path = in_dir\n",
    "_raw_paths = in_dir\n",
    "_processed_paths = [in_dir, out_dir]\n",
    "\n",
    "### Online Modified for local\n",
    "st = cutax.contexts.xenonnt_online(   _database_init              = _database_init,\n",
    "                                        we_are_the_daq              = we_are_the_daq,\n",
    "                                        output_folder               = output_folder,\n",
    "                                        include_rucio_remote        = include_rucio_remote,\n",
    "                                        include_online_monitor      = include_online_monitor,\n",
    "                                        include_rucio_local         = include_rucio_local,\n",
    "                                        download_heavy              = download_heavy,\n",
    "                                        _auto_append_rucio_local    = _auto_append_rucio_local,\n",
    "                                        _rucio_path                 = _rucio_path,\n",
    "                                        _rucio_local_path           = _rucio_local_path,\n",
    "                                        _raw_paths                  = _raw_paths,\n",
    "                                        _processed_paths            = _processed_paths,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ids = {}\n",
    "for i in os.listdir(in_dir):\n",
    "    split_str = i.split('-')\n",
    "    if len(split_str) == 3:\n",
    "        run_ids[split_str[0]] = 0\n",
    "run_ids = run_ids.keys()\n",
    "run_ids = list(run_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# About 2h to collect 14 or so datasets on server\n",
    "# Another 2h rsync\n",
    "# Processing : 1h20m? \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# At max 400GB a day, 300GB on a good day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed on 064662\n",
      "raw_records for 064662 not found in any storage, and your context specifies it cannot be created.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "save_path = \"/Code/processed_data\"\n",
    "\n",
    "vaild_ids = []\n",
    "for i in run_ids:\n",
    "    try:\n",
    "        if not os.path.isfile(os.path.join(save_path, i + '.hdf5')):\n",
    "            pat = st.get_array(str(i), max_workers = max_workers, targets='event_area_per_channel')\n",
    "            ei = st.get_array(str(i), targets='event_info')\n",
    "            if len(ei) > 4:\n",
    "                # Save as HDF5 as it takes very long to load local data\n",
    "                with h5py.File(os.path.join(save_path, i + '.hdf5'), 'w') as f:\n",
    "                    f.create_dataset('event_area_per_channel', data=pat)\n",
    "                    f.create_dataset('event_info', data=ei)\n",
    "                vaild_ids.append(i)\n",
    "    except Exception as e:\n",
    "        print(\"Failed on {}\".format(i))\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run ID checking and merging\n",
    "\n",
    "ID checking is unsuccessfull \n",
    "\n",
    "Just make a HDF5 file (keeping a backup), with the patterns and positions for each ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dir  = \"/Code/mnt_point\"\n",
    "out_dir = \"/Code/strax_data2\"\n",
    "\n",
    "max_workers = 25\n",
    "\n",
    "# Set up strax context\n",
    "_database_init = False\n",
    "we_are_the_daq = False\n",
    "# Differnt dir so we still ahve some usable data should something mess up bigtime\n",
    "output_folder = out_dir\n",
    "include_rucio_remote = False\n",
    "include_online_monitor = False\n",
    "include_rucio_local = False\n",
    "download_heavy = False\n",
    "_auto_append_rucio_local = False\n",
    "# Idk which of those is the correct one but it works\n",
    "_rucio_path = in_dir\n",
    "_rucio_local_path = in_dir\n",
    "_raw_paths = in_dir\n",
    "_processed_paths = [in_dir, out_dir]\n",
    "\n",
    "### Online Modified for local\n",
    "st = straxen.contexts.xenonnt_online(   _database_init              = _database_init,\n",
    "                                        we_are_the_daq              = we_are_the_daq,\n",
    "                                        output_folder               = output_folder,\n",
    "                                        include_rucio_remote        = include_rucio_remote,\n",
    "                                        include_online_monitor      = include_online_monitor,\n",
    "                                        include_rucio_local         = include_rucio_local,\n",
    "                                        download_heavy              = download_heavy,\n",
    "                                        _auto_append_rucio_local    = _auto_append_rucio_local,\n",
    "                                        _rucio_path                 = _rucio_path,\n",
    "                                        _rucio_local_path           = _rucio_local_path,\n",
    "                                        _raw_paths                  = _raw_paths,\n",
    "                                        _processed_paths            = _processed_paths,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "065091\n",
      "065090\n",
      "065089\n",
      "065065\n",
      "065062\n",
      "065061\n",
      "065060\n",
      "065057\n",
      "065056\n",
      "065055\n",
      "065052\n",
      "065051\n",
      "065050\n",
      "065047\n",
      "065046\n",
      "065045\n",
      "065042\n",
      "065041\n",
      "065040\n",
      "065037\n"
     ]
    }
   ],
   "source": [
    "# Make list of datasets not yet processed\n",
    "valid_ids = []\n",
    "save_path = \"/Code/processed_data\"\n",
    "all_ids = '/Code/runids.txt' # Contains all valid ids for the Xenon calibration data\n",
    "todo = []\n",
    "# Manually reject datasets\n",
    "flagged = []\n",
    "\n",
    "for i in os.listdir(save_path):\n",
    "    valid_ids.append(i.split('.')[0])\n",
    "all_ids_list = []\n",
    "with open(all_ids, 'r') as file:\n",
    "    for line in file:\n",
    "        all_ids_list.append(line.strip())\n",
    "\n",
    "for i in all_ids_list:\n",
    "    if i not in valid_ids and i not in flagged:\n",
    "        todo.append(i)\n",
    "\n",
    "# Only need 14 - 15 per 100GB\n",
    "for i in range(20):\n",
    "    print(todo[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['065091',\n",
       " '065090',\n",
       " '065089',\n",
       " '065065',\n",
       " '065062',\n",
       " '065061',\n",
       " '065060',\n",
       " '065057',\n",
       " '065056',\n",
       " '065055',\n",
       " '065052',\n",
       " '065051',\n",
       " '065050',\n",
       " '065047',\n",
       " '065046',\n",
       " '065045',\n",
       " '065042',\n",
       " '065041',\n",
       " '065040',\n",
       " '065037']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "todo[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "065036\n",
      "065035\n",
      "065032\n",
      "065031\n",
      "065030\n",
      "065024\n",
      "065019\n",
      "064771\n",
      "064768\n",
      "064767\n",
      "064766\n",
      "064763\n",
      "064762\n",
      "064761\n",
      "064758\n",
      "064757\n",
      "064756\n",
      "064753\n",
      "064752\n",
      "064751\n"
     ]
    }
   ],
   "source": [
    "for i in range(20, 40):\n",
    "    print(todo[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['065036',\n",
       " '065035',\n",
       " '065032',\n",
       " '065031',\n",
       " '065030',\n",
       " '065024',\n",
       " '065019',\n",
       " '064771',\n",
       " '064768',\n",
       " '064767',\n",
       " '064766',\n",
       " '064763',\n",
       " '064762',\n",
       " '064761',\n",
       " '064758',\n",
       " '064757',\n",
       " '064756',\n",
       " '064753',\n",
       " '064752',\n",
       " '064751']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "todo[20:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "064748\n",
      "064747\n",
      "064745\n",
      "064743\n",
      "064742\n",
      "064739\n",
      "064738\n",
      "064737\n",
      "064734\n",
      "064728\n",
      "064723\n",
      "064705\n",
      "064673\n",
      "064672\n",
      "064669\n",
      "064668\n",
      "064667\n",
      "064664\n",
      "064663\n",
      "064662\n"
     ]
    }
   ],
   "source": [
    "for i in range(40, 60):\n",
    "    print(todo[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['064748',\n",
       " '064747',\n",
       " '064745',\n",
       " '064743',\n",
       " '064742',\n",
       " '064739',\n",
       " '064738',\n",
       " '064737',\n",
       " '064734',\n",
       " '064728',\n",
       " '064723',\n",
       " '064705',\n",
       " '064673',\n",
       " '064672',\n",
       " '064669',\n",
       " '064668',\n",
       " '064667',\n",
       " '064664',\n",
       " '064663',\n",
       " '064662']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "todo[40:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preamble\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Within my docker image thats the path \n",
    "sys.path.append('/Code/Reimplementations/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihood Function Comparisons\n",
    "\n",
    "Here we compare the individual methods and assure that these produce the same outputs\n",
    "\n",
    "In order:\n",
    "- Tensorflow vs Jax\n",
    "- Jax vs Numpy\n",
    "- Numpy vs Numba\n",
    "\n",
    "The likelihood ratios show significant deviation (on a float precision level) but this is expected due to compounding errors\n",
    "\n",
    "TODO Need to implement MLE for exact for all three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dont need to use as many parameters as usually\n",
    "# And all but n_pmts are the default set of parameters used\n",
    "n_pmts = 100\n",
    "return_ratio = False \n",
    "switching_signal=40 \n",
    "n_sigma=5\n",
    "sigma_min=0.05 \n",
    "sigma_max=1 \n",
    "z=20\n",
    "p_dpe=0.2\n",
    "nan_safe=True \n",
    "nan_safe_value = 1e5 \n",
    "m=5\n",
    "mle_estimator = None\n",
    "\n",
    "# JAX implementation requirements (hardcoded in tf )\n",
    "obs_min = -3 \n",
    "\n",
    "# Range of Stds for evaluation \n",
    "stds = np.linspace(0.05, 0.95, n_pmts)\n",
    "stds = np.full((n_pmts,), 0.5)  # Use a constant value for all PMTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "# Reload all modules before running a cell\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow vs Jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 10:38:38.305635: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-04 10:38:38.369930: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-06-04 10:38:38.370098: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-06-04 10:38:38.372413: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-04 10:38:38.384248: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-04 10:38:40.018643: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nNotes on closeness of values\\n\\nGaussian component is equivalent using np.isclose \\nBinomial is close using rtol = 1.16e-5 and atol = 0 (around 2% of data tested)\\nPoisson is close using rtol = 5e-5 and atol = 0 \\n\\nExact Likelihood aligns with rtol = 3e-5 and atol = 0 \\n\\nLUT with rtol 3e-5 and atol = 0\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare Exact methods and LUT tables (both compute via exact and produce LUT)\n",
    "\n",
    "from TensorflowImplementation.LikelihoodFunction import LikelihoodRatio\n",
    "from JAXReimplementation import LikelihoodFunction as LikelihoodFunctionJAX\n",
    "\n",
    "\n",
    "tf_implement = LikelihoodRatio( n_pmts, \n",
    "                                return_ratio = return_ratio, \n",
    "                                switching_signal = switching_signal, \n",
    "                                n_sigma = n_sigma,\n",
    "                                sigma_min = sigma_min, \n",
    "                                sigma_max = sigma_max, \n",
    "                                z = z,\n",
    "                                p_dpe = p_dpe, \n",
    "                                nan_safe = nan_safe, \n",
    "                                nan_safe_value = nan_safe_value, \n",
    "                                m = m,  \n",
    "                                mle_estimator = mle_estimator, \n",
    "                              )\n",
    "# Precompute LUT table\n",
    "tf_implement.std.assign(stds)\n",
    "tf_implement.set_call_mode(\"LUT_untrainable_std\", return_ratio = True)\n",
    "\n",
    "tf_LUT = tf_implement.L_table\n",
    "tf_LUT_mle = tf_implement.L_mle_table\n",
    "tf_x_domain = tf_implement.x_domain\n",
    "tf_mu_domain = tf_implement.mu_domain\n",
    "\n",
    "jax_LUT, jax_LUT_MLE, jax_x_domain, jax_mu_domain = LikelihoodFunctionJAX.generate_LUT(\n",
    "    m = m,\n",
    "    p = p_dpe,\n",
    "    switching_signal = switching_signal,\n",
    "    gaussian_stds = stds,\n",
    "    n_sigma = n_sigma, \n",
    "    obs_min = obs_min\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "Notes on closeness of values\n",
    "\n",
    "Gaussian component is equivalent using np.isclose \n",
    "Binomial is close using rtol = 1.16e-5 and atol = 0 (around 2% of data tested)\n",
    "Poisson is close using rtol = 5e-5 and atol = 0 \n",
    "\n",
    "Exact Likelihood aligns with rtol = 3e-5 and atol = 0 \n",
    "\n",
    "LUT with rtol 3e-5 and atol = 0\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the two methods produce the same numerical results\n",
    "assert np.allclose(tf_x_domain, jax_x_domain), \"x domains do not match!\"\n",
    "assert np.allclose(tf_mu_domain, jax_mu_domain), \"mu domains do not match!\"\n",
    "assert np.allclose(jax_LUT, tf_LUT, rtol = 3e-5, atol=0), \"LUTs do not match!\"\n",
    "assert np.allclose(tf_LUT_mle, jax_LUT_MLE, rtol = 2e-5, atol=0), \"MLE LUTs do not match!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact only branch\n",
      "True\n",
      "Gaussian only branch\n",
      "True\n",
      "Mixed branch\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Now full chain with parent call exact\n",
    "tf_implement = LikelihoodRatio( n_pmts, \n",
    "                                return_ratio = return_ratio, \n",
    "                                switching_signal = switching_signal, \n",
    "                                n_sigma = n_sigma,\n",
    "                                sigma_min = sigma_min, \n",
    "                                sigma_max = sigma_max, \n",
    "                                z = z,\n",
    "                                p_dpe = p_dpe, \n",
    "                                nan_safe = nan_safe, \n",
    "                                nan_safe_value = nan_safe_value, \n",
    "                                m = m,  \n",
    "                                mle_estimator = mle_estimator, \n",
    "                              )\n",
    "tf_implement.std.assign(stds)\n",
    "tf_implement.set_call_mode(\"exact\", return_ratio = False)\n",
    "tf_implement.std.assign(stds)\n",
    "\n",
    "jax_implement = LikelihoodFunctionJAX.parent_gen(stds,\n",
    "                                                 method = 'Exact',\n",
    "                                                 return_ratio=False,\n",
    "                                                 switching_signal = switching_signal,\n",
    "                                                 p_dpe = p_dpe,\n",
    "                                                 n_sigma = n_sigma,\n",
    "                                                 m = m,\n",
    "                                                 )\n",
    "\n",
    "# Generate some random data to test\n",
    "n_samples = 1000\n",
    "x= np.random.uniform(-3,40, size=n_samples * n_pmts).reshape(n_samples, n_pmts).astype('float32')\n",
    "mu = np.clip(x, 0, None) / np.sum(np.where(x >= 0, x, 0), axis=1, keepdims=True)  # Normalize mu to sum to 1\n",
    "\n",
    "res1 = tf_implement(mu, x)\n",
    "res2 = jax_implement(x = x, mu = mu)\n",
    "print(\"Exact only branch\")\n",
    "print(np.allclose(res1, res2))\n",
    "\n",
    "n_samples = 1000\n",
    "x= np.random.uniform(40,1000, size=n_samples * n_pmts).reshape(n_samples, n_pmts).astype('float32')\n",
    "mu = x / np.sum(np.where(x >= 0, x, 0), axis=1, keepdims=True)  # Normalize mu to sum to 1\n",
    "\n",
    "res1 = tf_implement(mu, x)\n",
    "res2 = jax_implement(x = x, mu = mu)\n",
    "\n",
    "print(\"Gaussian only branch\")\n",
    "print(np.allclose(res1, res2))\n",
    "\n",
    "n_samples = 1000\n",
    "x= np.random.uniform(-3,100, size=n_samples * n_pmts).reshape(n_samples, n_pmts).astype('float32')\n",
    "mu = x / np.sum(np.where(x >= 0, x, 0), axis=1, keepdims=True)  # Normalize mu to sum to 1\n",
    "\n",
    "res1 = tf_implement(mu, x)\n",
    "res2 = jax_implement(x = x, mu = mu)\n",
    "\n",
    "print(\"Mixed branch\")\n",
    "print(np.allclose(res1, res2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact only branch\n",
      "False\n",
      "0.9858\n",
      "Gaussian only branch\n",
      "False\n",
      "0.39616\n",
      "Mixed branch\n",
      "False\n",
      "0.64576\n"
     ]
    }
   ],
   "source": [
    "from TensorflowImplementation.LikelihoodFunction import LikelihoodRatio\n",
    "from JAXReimplementation import LikelihoodFunction as LikelihoodFunctionJAX\n",
    "\n",
    "# Now full chain with parent call on LUT\n",
    "tf_implement = LikelihoodRatio( n_pmts, \n",
    "                                return_ratio = True, \n",
    "                                switching_signal = switching_signal, \n",
    "                                n_sigma = n_sigma,\n",
    "                                sigma_min = sigma_min, \n",
    "                                sigma_max = sigma_max, \n",
    "                                z = z,\n",
    "                                p_dpe = p_dpe, \n",
    "                                nan_safe = False, \n",
    "                                nan_safe_value = nan_safe_value, \n",
    "                                m = m,  \n",
    "                                mle_estimator = mle_estimator, \n",
    "                              )\n",
    "tf_implement.std.assign(stds)\n",
    "tf_implement.set_call_mode(\"LUT_untrainable_std\", return_ratio = True)\n",
    "\n",
    "jax_implement = LikelihoodFunctionJAX.parent_gen(stds,\n",
    "                                                 method = 'LUT',\n",
    "                                                 return_ratio=True,\n",
    "                                                 switching_signal = switching_signal,\n",
    "                                                 p_dpe = p_dpe,\n",
    "                                                 n_sigma = n_sigma,\n",
    "                                                 m = m,\n",
    "                                                 )\n",
    "\n",
    "# Generate some random data to test\n",
    "n_samples = 1000\n",
    "x= np.random.uniform(-3,40, size=n_samples * n_pmts).reshape(n_samples, n_pmts).astype('float32')\n",
    "mu = np.clip(x, 0, None) / np.sum(np.where(x >= 0, x, 0), axis=1, keepdims=True)  # Normalize mu to sum to 1\n",
    "\n",
    "res1 = tf_implement(mu, x)\n",
    "res2 = jax_implement(x = x, mu = mu)\n",
    "print(\"Exact only branch\")\n",
    "print(np.allclose(res1, res2, rtol = 3e-5, atol=0))\n",
    "print(np.isclose(res1, res2, rtol = 3e-5, atol=0).mean())\n",
    "\n",
    "n_samples = 1000\n",
    "x= np.random.uniform(40,1000, size=n_samples * n_pmts).reshape(n_samples, n_pmts).astype('float32')\n",
    "mu = x / np.sum(np.where(x >= 0, x, 0), axis=1, keepdims=True)  # Normalize mu to sum to 1\n",
    "\n",
    "res1 = tf_implement(mu, x)\n",
    "res2 = jax_implement(x = x, mu = mu)\n",
    "\n",
    "print(\"Gaussian only branch\")\n",
    "print(np.allclose(res1, res2, rtol = 3e-5, atol=0))\n",
    "print(np.isclose(res1, res2, rtol = 3e-5, atol=0).mean())\n",
    "\n",
    "n_samples = 1000\n",
    "x= np.random.uniform(-3,100, size=n_samples * n_pmts).reshape(n_samples, n_pmts).astype('float32')\n",
    "mu = np.clip(x, 0, None) / np.sum(np.where(x >= 0, x, 0), axis=1, keepdims=True)  # Normalize mu to sum to 1\n",
    "\n",
    "res1 = tf_implement(mu, x)\n",
    "res2 = jax_implement(x = x, mu = mu)\n",
    "\n",
    "print(\"Mixed branch\")\n",
    "print(np.allclose(res1, res2, rtol = 3e-5, atol=0))\n",
    "print(np.isclose(res1, res2, rtol = 3e-5, atol=0).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guassian Likelihood\n",
      "True\n",
      "Guassian MLE Likelihood\n",
      "True\n",
      "Loss function Gaussian\n",
      "False\n",
      "0.49015\n",
      "max relative diff: 0.2413793\n",
      "Sanity Check\n",
      "NLLR Gaussian\n",
      "False\n",
      "0.49015\n",
      "max relative diff: 0.2413793\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAMWCAYAAADs4eXxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAACSIklEQVR4nOzdeVxU9f7H8fcAAziIoykopiEqmbiguZWmYW65VZpl3so1r10hLbRutrjfTEvTkjQrNcvSSrPVFTPLTHHBMs2lTFtQcQMBBYTz+8MfkyOggHMcgdfz8ZhHzPd853w/szD55nvO91gMwzAEAAAAAABczsPdBQAAAAAAUFIRugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMImXuwtwt+zsbP3999/y9/eXxWJxdzkAAAAAgGLAMAydPn1aVatWlYdH/vPZpT50//3336pevbq7ywAAAAAAFEN//PGHqlWrlu/2Uh+6/f39JZ1/ocqVK+fmagAAAAAAxUFycrKqV6/uyJT5KfWhO+eQ8nLlyhG6AQAAAACFcrnTlEvtQmoxMTEKCwtTs2bN3F0KAAAAAKCEshiGYbi7CHdKTk6W3W5XUlISM90AAAAAgAIpaJYstTPdAAAAAACYrdSf0w0AAADg6sjOzlZGRoa7ywAKxGq1ytPT84r3Q+gGAAAAYLqMjAwdOHBA2dnZ7i4FKLDy5curSpUql10s7VII3QAAAABMZRiGEhIS5OnpqerVq8vDg7NccW0zDENpaWk6evSoJCkoKKjI+yJ0AwAAADDVuXPnlJaWpqpVq8pms7m7HKBAypQpI0k6evSoAgMDi3yoOX9iAgAAAGCqrKwsSZK3t7ebKwEKJ+ePRJmZmUXeB6EbAAAAwFVxJefFAu7gis8soRsAAAAAAJMQugEAAAAA16waNWpo+vTp7i6jyFhIDQAAAIBbjB177Y53ucOKx4wZo/79+yskJCTXtgcffFDvvfdeno+LiIhQo0aNrpkQuWTJEsXExGj79u06e/asbrjhBrVq1UqPPfaYGjdu7O7yJElxcXHy8/NzdxlFRugGAAAAgIskJCQ4fl68eLFGjx6tPXv2ONrKli2rY8eOSZLWrFmjevXqObblrHp9rfvvf/+rqVOnatiwYRo3bpyCg4OVmJio5cuXa9SoUVqxYoW7S5QkBQQEuLuEK8Lh5QAAAABwkSpVqjhudrtdFovFqa1s2bKOvhUrVszVv6iWLFmievXqycfHRzVq1NDUqVOdtr/++usKDQ2Vr6+vKleurF69ejm2ffzxx2rQoIHKlCmjihUrqn379kpNTc1znB9++EFTpkzRtGnTNG3aNLVu3Vo33HCDmjRpoueee07Lly939P3111919913q3LlyipbtqyaNWumNWvWOO3PYrFo2bJlTm3ly5fX/PnzJUkZGRmKiopSUFCQfH19FRwcrEmTJkk6f03ssWPH6oYbbpCPj4+qVq2qYcOGOfZz8eHl06ZNU4MGDeTn56fq1atr6NChSklJcWyfP3++ypcvr5UrV6pu3boqW7as7rzzTqc/pFxNhG4AAAAAuAZs3bpV999/vx544AH99NNPGjt2rJ5//nlHcN2yZYuGDRum8ePHa8+ePVqxYoXatGkj6fzMfJ8+fTRw4EDt3r1b69atU8+ePWUYRp5jffDBBypbtqyGDh2a5/YLD69PSUlRly5dFBsbq+3bt+vOO+9U9+7ddejQoQI/t1dffVWfffaZPvzwQ+3Zs0cLFy5UjRo1JJ3/Q8Mrr7yiN954Q/v27dOyZcvUoEGDfPfl4eGhV199VT///LPeeecdrV27Vk899ZRTn7S0NL388st69913tX79eh06dEgjR44scL2uxOHlAAAAAHAFWrZsKQ+Pf+Yzv/322yKdDz1t2jS1a9dOzz//vCTpxhtv1K5du/TSSy+pf//+OnTokPz8/NStWzf5+/srODjYMU5CQoLOnTunnj17Kjg4WJIuGVz37t2rmjVrysvrn0g4bdo0jR492nH/r7/+kt1uV3h4uMLDwx3tEyZM0CeffKLPPvtMUVFRBXpuhw4dUmhoqG677TZZLBZHjTnbqlSpovbt28tqteqGG25Q8+bN893X448/7vi5Ro0amjhxoh599FG9/vrrjvbMzEzNnj1btWrVkiRFRUVp/PjxBarV1UrtTHdMTIzCwsLUrFkzd5cCAAAAoBhbvHix4uPjHbewsLAi7Wf37t1q1aqVU1urVq20b98+ZWVlqUOHDgoODlbNmjX18MMPa+HChUpLS5MkhYeHq127dmrQoIHuu+8+vfnmmzp58mShxh84cKDi4+P1xhtvKDU11TFLnpKSopEjR6pu3boqX768ypYtq927dxdqprt///6Kj49XnTp1NGzYMK1atcqx7b777tOZM2dUs2ZNDR48WJ988onOnTuX777WrFmjdu3a6frrr5e/v78efvhhHT9+3PFaSJLNZnMEbkkKCgrS0aNHC/NyuEypDd2RkZHatWuX4uLi3F0KAAAAgGKsevXqql27tuPm4+Njyjj+/v7atm2bPvjgAwUFBWn06NEKDw/XqVOn5OnpqdWrV2v58uUKCwvTa6+9pjp16ujAgQN57is0NFS//fabMjMzHW3ly5dX7dq1df311zv1HTlypD755BO98MIL+vbbbxUfH68GDRooIyPD0cdiseQ6lP3Cfd988806cOCAJkyYoDNnzuj+++93nI9evXp17dmzR6+//rrKlCmjoUOHqk2bNk6Pz/H777+rW7duatiwoZYsWaKtW7cqJiZGkpzqsVqtTo/Lq76rpdSGbkhKSpISEv65JSUVbjsAAAAAl6lbt642bNjg1LZhwwbdeOON8vT0lCR5eXmpffv2mjJlin788Uf9/vvvWrt2raTzwbJVq1YaN26ctm/fLm9vb33yySd5jtWnTx+lpKQ4HZKdnw0bNqh///7q0aOHGjRooCpVquj333936hMQEOC0UNm+ffucZp4lqVy5curdu7fefPNNLV68WEuWLNGJEycknV/xvXv37nr11Ve1bt06bdy4UT/99FOuWrZu3ars7GxNnTpVt9xyi2688Ub9/fffl30O7sQ53aVJUpKU88FPTVXsvxfLM/ufvx5FdLBKvXtLfn75b4+Kki61GuOFY0iSzXbp/gAAAEApk5iYqPj4eKe2oKAgjRgxQs2aNdOECRPUu3dvbdy4UTNnznQE4y+++EK//fab2rRpowoVKuirr75Sdna26tSpo02bNik2NlYdO3ZUYGCgNm3apMTERNWtWzfPGm699VaNGDFCI0aM0MGDB9WzZ09Vr15dCQkJevvtt2WxWBznqYeGhmrp0qXq3r27LBaLnn/+eWVnZzvt74477tDMmTN16623KisrS//973+dZpunTZumoKAgNW7cWB4eHvroo49UpUoVxwrnWVlZatGihWw2m9577z2VKVPG6bzvHLVr11ZmZqZee+01de/eXRs2bNDs2bOv5O0wHaG7JLtMyJaHVT82fEgZVj95Z6YqK3axPFe/l+d2v7RERWQulQ4elC68Tt6FoTopSbE9ZuYf5PNiRign+AMAAOAa9v777+v99993apswYYKee+45ffjhhxo9erQmTJigoKAgjR8/Xv3795d0/vDvpUuXauzYsTp79qxCQ0P1wQcfqF69etq9e7fWr1+v6dOnKzk5WcHBwZo6dao6d+6cbx0vv/yymjdvrlmzZmnu3LlKS0tT5cqV1aZNG23cuFHlypWTdD4wDxw4UC1btlSlSpX03//+V8nJyU77mjp1qgYMGKDWrVuratWqmjFjhrZu3erY7u/vrylTpmjfvn3y9PRUs2bN9NVXX8nDw0Ply5fXiy++qOjoaGVlZalBgwb6/PPPVbFixVw1h4eHa9q0aZo8ebJGjRqlNm3aaNKkSerbt29R3w7TWQx3Hdh+jUhOTpbdbldSUpLjQ1VsXSZkZ3lY9XP93sqwng/AmVab0n3/CaM+Z5NkzfwnrF643edskppvdg7U0kWhOjFR64Yt1e66PZVqC5B3Zqrq7Vyc6zG5Hn+52fNLPU+p8MGfEA4AAHBVnT17VgcOHFBISIh8fX3dXQ5QYJf67BY0SzLTXVxdHDwvM5Mt5Q7ZF0v3tee7Pd3Xrs3No5xCeV6z41keVp2yBzv2c/FjLpTv7PmlpKZKixdLFy6qYHUO/p7ZmU7B/+Ia85x9vziImzFbzgw8AAAAUOoQuoujPGZzJRU6ZBdWXqH84lB98ZiXCvKZVpti11vluW5poeo4P2P/z2Hx9XYWPPjneRi9XHQ++6UU5dD7yylKaCf4AwAAAFcVobs4Sktzms3N4eqQXRCXCtUFeeylZsLzc/HzLGzwL8iM/WXPZ79cWL043BZgBr6wCh3aL7d4nkQIBwAAAFyM0F2MpdoClOIf5O4yrsiVhPai7qOwM/Z5zchfMvDmdai/Cnfo/eUUObRfZvG8K57RBwAAAOCE0A2ocOezFyjwXnSov1S4Q+8LwtVHCThm9NPSCN0AAACAixC6gQK43CHqF7sah/q74ygBAAAAAIVD6AaKgLAKAAAAoCA83F0AAAAAAAAlFaEbAAAAAFCs9O/fX/fcc4+7yygQQjcAAAAA90hKkhISrt4tKalQ5eUV7CZNmiRPT0+99NJLufr/97//VY0aNXT69Gmn9u7du6tNmzbKzs7Oc5yxY8eqUaNGharNTNu3b1fv3r0VFBQkHx8fBQcHq1u3bvr8889lGIa7y5MkzZgxQ/Pnz3d3GQXCOd0AAAAArr6kJGnmTCkz8/J9XcV65ZdHnTt3rp566inNnTtXTz75pNO28ePH68svv1R0dLTefPNNR/+vv/5aO3bskIfHtT/n+emnn+r+++9X+/bt9c4776h27dpKT0/X999/r+eee06tW7dW+fLl3V2m7MXoajuEbgAAAABXX1ra+cDds6cUEGD+eImJ0tIruzzqN998ozNnzmj8+PFasGCBvv/+e7Vs2dKx3cfHR++8845uvfVW3XvvvQoLC9MTTzyhKVOmqFatWkUu/aefftLw4cO1ceNG2Ww23XvvvZo2bZrKli0rSVq3bp2eeuop/fzzz7JarapXr57ef/99BQcHa8eOHXr88ce1ZcsWWSwWhYaG6o033lDTpk1zjZOamqpBgwapa9euWrp0qdO2unXratCgQY6Z7qysLP373//W2rVrdfjwYd1www0aOnSohg8f7nhMRESEGjVqpOnTpzva7rnnHpUvX94xS/3666/rlVde0R9//CG73a7WrVvr448/liR9/PHHGjdunPbv3y+bzabGjRvr008/lZ+fn/r3769Tp05p2bJlkqQVK1Zo4sSJ2rlzpzw9PXXrrbdqxowZjtf9999/V0hIiJYsWaLXXntNmzZtUmhoqGbPnq1bb721yO9NQRC6AQAAALhPQIAUFOTuKgrk7bffVp8+fWS1WtWnTx+9/fbbTqFbkpo0aaJRo0bpkUceUa1atdS8eXP95z//KfKYqamp6tSpk2699VbFxcXp6NGjeuSRRxQVFaX58+fr3LlzuueeezR48GB98MEHysjI0ObNm2WxWCRJDz74oBo3bqxZs2bJ09NT8fHxslqteY61atUqHT9+XE899VS+9eTsNzs7W9WqVdNHH32kihUr6vvvv9e///1vBQUF6f777y/Qc9uyZYuGDRumd999Vy1bttSJEyf07bffSpISEhLUp08fTZkyRT169NDp06f17bff5nt4e2pqqqKjo9WwYUOlpKRo9OjR6tGjh+Lj452OMHj22Wf18ssvKzQ0VM8++6z69Omj/fv3y8vLvGhM6AYAAACAy0hOTtbHH3+sjRs3SpIeeughtW7dWjNmzHDMOOd47rnnNG/ePG3atEl79+51BNWieP/993X27FktWLBAfn5+kqSZM2eqe/fumjx5sqxWq5KSktStWzfHrG7dunUdjz906JCefPJJ3XTTTZKk0NDQfMfau3evJKlOnTqOtri4OLVt29Zxf9GiRerWrZusVqvGjRvnaA8JCdHGjRv14YcfFjh0Hzp0SH5+furWrZv8/f0VHBysxo0bSzofus+dO6eePXsqODhYktSgQYN893Xvvfc63Z87d64CAgK0a9cu1a9f39E+cuRIde3aVZI0btw41atXT/v373e8Pma49k8qAAAAAAA3++CDD1SrVi2Fh4dLkho1aqTg4GAtXrw4V9/Vq1fr8OHDys7OVlxc3BWNu3v3boWHhzsCtyS1atVK2dnZ2rNnj6677jr1799fnTp1Uvfu3TVjxgwlJCQ4+kZHR+uRRx5R+/bt9eKLL+rXX38t1PgNGzZUfHy84uPjlZqaqnPnzjm2xcTEqEmTJgoICFDZsmU1Z84cHTp0qMD77tChg4KDg1WzZk09/PDDWrhwodLS0iRJ4eHhateunRo0aKD77rtPb775pk6ePJnvvvbt26c+ffqoZs2aKleunGrUqCFJuepp2LCh4+eg/z/C4ujRowWuuSgI3QAAAABwGW+//bZ+/vlneXl5OW67du3S3LlznfqdPHlSgwcP1nPPPadnn31WQ4cO1bFjx0ytbd68edq4caNatmypxYsX68Ybb9QPP/wg6fzK6D///LO6du2qtWvXKiwsTJ988kme+8mZBd+zZ4+jzcfHR7Vr11bt2rWd+i5atEgjR47UoEGDtGrVKsXHx2vAgAHKyMhw9PHw8Mh1OHjmBQvn+fv7a9u2bfrggw8UFBSk0aNHKzw8XKdOnZKnp6dWr16t5cuXKywsTK+99prq1KmjAwcO5Fl79+7ddeLECb355pvatGmTNm3aJElO9UhyOrT+wkPlzUToLi4uvJxCYqK7qwEAAABKjZ9++klbtmzRunXrHLO+8fHxWrdunTZu3KhffvnF0fexxx5TlSpV9Mwzz+jZZ5/V9ddfr8jIyCKPXbduXe3YsUOpqamOtg0bNsjDw8PpMPDGjRtr1KhR+v7771W/fn29//77jm033nijnnjiCa1atUo9e/bUvHnz8hyrY8eOuu666zR58uTL1rVhwwa1bNlSQ4cOVePGjVW7du1cs+gBAQFOs+5ZWVnauXOnUx8vLy+1b99eU6ZM0Y8//qjff/9da9eulXQ+FLdq1Urjxo3T9u3b5e3tnecfDI4fP649e/boueeeU7t27VS3bt1LzopfbaX2nO6YmBjFxMQoKyvL3aVcXh6XU8jysCrTanNjUQAAAEDp8Pbbb6t58+Zq06ZNrm3NmjXT22+/rZdeekmffPKJPvroI23dutWxMNc777yjpk2basmSJbnOO77QmTNnFB8f79Tm7++vBx98UGPGjFG/fv00duxYJSYm6rHHHtPDDz+sypUr68CBA5ozZ47uuusuVa1aVXv27NG+ffvUt29fnTlzRk8++aR69eqlkJAQ/fnnn4qLi8u3jrJly+qtt95S79691bVrVw0bNkyhoaFKSUnRihUrJEmenp6Szs+KL1iwQCtXrlRISIjeffddxcXFKSQkxLG/O+64Q9HR0fryyy9Vq1YtTZs2TadOnXJs/+KLL/Tbb7+pTZs2qlChgr766itlZ2erTp062rRpk2JjY9WxY0cFBgZq06ZNSkxMdDpfPUeFChVUsWJFzZkzR0FBQTp06JCefvrpfF/rq63Uhu7IyEhFRkYqOTn52r/GW1qa1q3O1O66PZVqO385hczmNqX7XuN1AwAAAJdztY7iLMI42dnZ8vDw0Hvvvaf//ve/efa59957NXXqVD311FN69NFHNWbMGKeFuxo0aKAxY8Zo6NChuv3221WpUqU897N3717HImI52rVrpzVr1mjlypUaPny4mjVr5nTJMEmy2Wz65Zdf9M477+j48eMKCgpSZGSkhgwZonPnzun48ePq27evjhw5okqVKqlnz55OC6BdrEePHvr+++81efJk9e3bVydOnJDdblfTpk0di6hJ0pAhQ7R9+3b17t1bFotFffr00dChQ7V8+XLHvgYOHKgdO3aob9++8vLy0hNPPOG0KFv58uW1dOlSjR07VmfPnlVoaKg++OAD1atXT7t379b69es1ffp0JScnKzg4WFOnTlXnzp1z1ezh4aFFixZp2LBhql+/vurUqaNXX31VERER+T7Pq8li5LfmeimRE7qTkpJUrlw5d5eTt4QErevzhrY0GaIU/+JxOQUUP2VPJ2ik/xvSkCHF5rIdAACgeDh79qwOHDigkJAQ+fr6nm/M42hO01mtUlRUga/Tfeedd6p27dqaOXOmyYXhWpXnZ/f/FTRLltqZbgAAAABuZLefD8D/v1r1VWGzFShwnzx5Uhs2bNC6dev06KOPXoXCUJIRugEAAAC4h91e4Fnnq2ngwIGKi4vTiBEjdPfdd7u7HBRzhG4AAAAAuEB+l9QCioJLhgEAAAAAYBJCNwAAAAAAJiF0AwAAALgqSvmFk1AMueIzS+gGAAAAYCpPT09JUkZGhpsrAQon7f9X17darUXeBwupAQAAADCVl5eXbDabEhMTZbVa5eHB3B+ubYZhKC0tTUePHlX58uUdfzgqCkI3AAAAAFNZLBYFBQXpwIEDOnjwoLvLAQqsfPnyqlKlyhXtg9ANAAAAwHTe3t4KDQ3lEHMUG1ar9YpmuHMQugEAAABcFR4eHvL19XV3GcBVxckUAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASbzcXQCAa0xi4j8/22yS3e6+WgAAAIBijtANQJKUabUpdr1VnuuWOtoiOlilqCiCNwAAAFBEhG4AkqR0X7s2N4+SNTNNkuSXlqiIzKVSWhqhGwAAACgiQjcAh3Rfu9J9CdgAAACAq7CQGgAAAAAAJiF0AwAAAABgkmIfuk+dOqWmTZuqUaNGql+/vt588013lwQAAAAAgKQScE63v7+/1q9fL5vNptTUVNWvX189e/ZUxYoV3V0aAAAAAKCUK/Yz3Z6enrLZbJKk9PR0GYYhwzDcXBUAAAAAANdA6F6/fr26d++uqlWrymKxaNmyZbn6xMTEqEaNGvL19VWLFi20efNmp+2nTp1SeHi4qlWrpieffFKVKlW6StUDAAAAAJA/t4fu1NRUhYeHKyYmJs/tixcvVnR0tMaMGaNt27YpPDxcnTp10tGjRx19ypcvrx07dujAgQN6//33deTIkatVPgAAAAAA+XJ76O7cubMmTpyoHj165Ll92rRpGjx4sAYMGKCwsDDNnj1bNptNc+fOzdW3cuXKCg8P17fffpvveOnp6UpOTna6AQAAAABgBreH7kvJyMjQ1q1b1b59e0ebh4eH2rdvr40bN0qSjhw5otOnT0uSkpKStH79etWpUyfffU6aNEl2u91xq169urlPAgAAAABQal3TofvYsWPKyspS5cqVndorV66sw4cPS5IOHjyo1q1bKzw8XK1bt9Zjjz2mBg0a5LvPUaNGKSkpyXH7448/TH0OAAAAAIDSq9hfMqx58+aKj48vcH8fHx/5+PiYVxAAAAAAAP/vmp7prlSpkjw9PXMtjHbkyBFVqVLFTVUBAAAAAFAw13To9vb2VpMmTRQbG+toy87OVmxsrG699VY3VgYAAAAAwOW5/fDylJQU7d+/33H/wIEDio+P13XXXacbbrhB0dHR6tevn5o2barmzZtr+vTpSk1N1YABA9xYNQAAAAAAl+f20L1lyxa1bdvWcT86OlqS1K9fP82fP1+9e/dWYmKiRo8ercOHD6tRo0ZasWJFrsXVCismJkYxMTHKysq6ov0AAAAAAJAfi2EYhruLcKfk5GTZ7XYlJSWpXLly7i4nbwkJWtfnDW1pMkQp/kHurgalRNnTCRrp/4Y0ZIgUxOcOAAAAuFBBs+Q1fU43AAAAAADFGaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJOU2tAdExOjsLAwNWvWzN2lAAAAAABKqFIbuiMjI7Vr1y7FxcW5uxQAAAAAQAlVakM3AAAAAABmI3QDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgklIburlONwAAAADAbKU2dHOdbgAAAACA2Upt6AYAAAAAwGyEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExSakM31+kGAAAAAJit1IZurtMNAAAAADBbqQ3dAAAAAACYjdANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJSm3ojomJUVhYmJo1a+buUgAAAAAAJVSpDd2RkZHatWuX4uLi3F0KAAAAAKCEKrWhGwAAAAAAsxG6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJOU2tAdExOjsLAwNWvWzN2lAAAAAABKqFIbuiMjI7Vr1y7FxcW5uxQAAAAAQAlVakM3AAAAAABmI3QDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGCSUhu6Y2JiFBYWpmbNmrm7FAAAAABACVVqQ3dkZKR27dqluLg4d5cCAAAAACihSm3oBgAAAADAbIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCRe7i4AwDUuMfGfn202yW53Xy0AAABAMUPoBpCnTKtNseut8ly31NEW0cEqRUURvAEAAIACInQDyFO6r12bm0fJmpkmSfJLS1RE5lIpLY3QDQAAABQQoRtAvtJ97Ur3JWADAAAARcVCagAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJik1IbumJgYhYWFqVmzZu4uBQAAAABQQpXa0B0ZGaldu3YpLi7O3aUAAAAAAEqoUhu6AQAAAAAwG6EbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTeLm7AADFTGKi832bTbLb3VMLAAAAcI0jdAMokEyrTbHrrfJct9SpPaKDVYqKIngDAAAAeSB0AyiQdF+7NjePkjUzzdHml5aoiMylUloaoRsAAADIA6EbQIGl+9qV7ku4BgAAAAqq2C+k9scffygiIkJhYWFq2LChPvroI3eXBAAAAACApBIw0+3l5aXp06erUaNGOnz4sJo0aaIuXbrIz8/P3aUBAAAAAEq5Yh+6g4KCFBQUJEmqUqWKKlWqpBMnThC6AQAAAABu5/bDy9evX6/u3buratWqslgsWrZsWa4+MTExqlGjhnx9fdWiRQtt3rw5z31t3bpVWVlZql69uslVAwAAAABweW4P3ampqQoPD1dMTEye2xcvXqzo6GiNGTNG27ZtU3h4uDp16qSjR4869Ttx4oT69u2rOXPmXI2yAQAAAAC4LLeH7s6dO2vixInq0aNHntunTZumwYMHa8CAAQoLC9Ps2bNls9k0d+5cR5/09HTdc889evrpp9WyZcurVToAAAAAAJfk9tB9KRkZGdq6davat2/vaPPw8FD79u21ceNGSZJhGOrfv7/uuOMOPfzww5fdZ3p6upKTk51uAAAAAACY4ZoO3ceOHVNWVpYqV67s1F65cmUdPnxYkrRhwwYtXrxYy5YtU6NGjdSoUSP99NNP+e5z0qRJstvtjhvnfwMAAAAAzFKk1ct/++031axZ09W1FMltt92m7OzsAvcfNWqUoqOjHfeTk5MJ3gAAAAAAUxRpprt27dpq27at3nvvPZ09e9bVNTlUqlRJnp6eOnLkiFP7kSNHVKVKlSLt08fHR+XKlXO6AQAAAABghiKF7m3btqlhw4aKjo5WlSpVNGTIkHwv43UlvL291aRJE8XGxjrasrOzFRsbq1tvvdXl4wEAAAAA4EpFCt2NGjXSjBkz9Pfff2vu3LlKSEjQbbfdpvr162vatGlKTEws8L5SUlIUHx+v+Ph4SdKBAwcUHx+vQ4cOSZKio6P15ptv6p133tHu3bv1n//8R6mpqRowYEBRSgcAAAAA4Kq5ooXUvLy81LNnT3300UeaPHmy9u/fr5EjR6p69erq27evEhISLruPLVu2qHHjxmrcuLGk8yG7cePGGj16tCSpd+/eevnllzV69Gg1atRI8fHxWrFiRa7F1QorJiZGYWFhatas2RXtBwAAAACA/FgMwzCK+uAtW7Zo7ty5WrRokfz8/NSvXz8NGjRIf/75p8aNG6fk5GRTDjt3peTkZNntdiUlJV2753cnJGhdnze0pckQpfgHubsawKHs6QSN9H9DGjJECuKzCQAAgNKjoFmySKuXT5s2TfPmzdOePXvUpUsXLViwQF26dJGHx/mJ85CQEM2fP181atQoUvEAAAAAAJQERQrds2bN0sCBA9W/f38F5TO7FRgYqLfffvuKigMAAAAAoDgrUujet2/fZft4e3urX79+Rdk9AAAAAAAlQpEWUps3b54++uijXO0fffSR3nnnnSsuCgAAAACAkqBIoXvSpEmqVKlSrvbAwEC98MILV1wUAAAAAAAlQZEOLz906JBCQkJytQcHBzuur32ti4mJUUxMjLKystxdClD8JSb+87PNJtnt7qsFAAAAuIYUKXQHBgbqxx9/zLU6+Y4dO1SxYkVX1GW6yMhIRUZGOpZ5B1B4mVabYtdb5bluqaMtooNViooieAMAAAAqYuju06ePhg0bJn9/f7Vp00aS9M0332j48OF64IEHXFoggGtXuq9dm5tHyZqZJknyS0tUROZSKS2N0A0AAACoiKF7woQJ+v3339WuXTt5eZ3fRXZ2tvr27cs53UApk+5rV7ovARsAAADIS5FCt7e3txYvXqwJEyZox44dKlOmjBo0aKDg4GBX1wcAAAAAQLFVpNCd48Ybb9SNN97oqloAAAAAAChRihS6s7KyNH/+fMXGxuro0aPKzs522r527VqXFAcAAAAAQHFWpNA9fPhwzZ8/X127dlX9+vVlsVhcXZfpuGQYAAAAAMBsRQrdixYt0ocffqguXbq4up6rhkuGAQAAAADM5lGUB3l7e6t27dqurgUAAAAAgBKlSKF7xIgRmjFjhgzDcHU9AAAAAACUGEU6vPy7777T119/reXLl6tevXqyWq1O25cuXeqS4gAAAAAAKM6KFLrLly+vHj16uLoWAAAAAABKlCKF7nnz5rm6DgAAAAAASpwindMtSefOndOaNWv0xhtv6PTp05Kkv//+WykpKS4rDgAAAACA4qxIM90HDx7UnXfeqUOHDik9PV0dOnSQv7+/Jk+erPT0dM2ePdvVdQIAAAAAUOwUaaZ7+PDhatq0qU6ePKkyZco42nv06KHY2FiXFWemmJgYhYWFqVmzZu4uBQAAAABQQhVppvvbb7/V999/L29vb6f2GjVq6K+//nJJYWaLjIxUZGSkkpOTZbfb3V0OULIkJv7zs80m8TsGAACAUqpIoTs7O1tZWVm52v/880/5+/tfcVEAiqdMq02x663yXPfPZQMjOlilqCiCNwAAAEqlIoXujh07avr06ZozZ44kyWKxKCUlRWPGjFGXLl1cWiCA4iPd167NzaNkzUyTJPmlJSoic6mUlkboBgAAQKlUpNA9depUderUSWFhYTp79qz+9a9/ad++fapUqZI++OADV9cIoBhJ97Ur3ZeADQAAAEhFDN3VqlXTjh07tGjRIv34449KSUnRoEGD9OCDDzotrAYAAAAAQGlWpNAtSV5eXnrooYdcWQsAAAAAACVKkUL3ggULLrm9b9++RSoGAAAAAICSpEihe/jw4U73MzMzlZaWJm9vb9lsNkI3AAAAAACSPIryoJMnTzrdUlJStGfPHt12220spAYAAAAAwP8rUujOS2hoqF588cVcs+DXqpiYGIWFhalZs2buLgUAAAAAUEK5LHRL5xdX+/vvv125S9NERkZq165diouLc3cpAAAAAIASqkjndH/22WdO9w3DUEJCgmbOnKlWrVq5pDAAAAAAAIq7IoXue+65x+m+xWJRQECA7rjjDk2dOtUVdQEAAAAAUOwVKXRnZ2e7ug4AJVli4j8/22yS3e6+WgAAAICrqEihGwAKItNqU+x6qzzXLXW0RXSwSlFRBG8AAACUCkUK3dHR0QXuO23atKIMAaAESPe1a3PzKFkz0yRJfmmJishcKqWlEboBAABQKhQpdG/fvl3bt29XZmam6tSpI0nau3evPD09dfPNNzv6WSwW11QJoNhK97Ur3ZeADQAAgNKpSKG7e/fu8vf31zvvvKMKFSpIkk6ePKkBAwaodevWGjFihEuLBAAAAACgOCrSdbqnTp2qSZMmOQK3JFWoUEETJ05k9XIAAAAAAP5fkUJ3cnKyEi9cjfj/JSYm6vTp01dcFAAAAAAAJUGRQnePHj00YMAALV26VH/++af+/PNPLVmyRIMGDVLPnj1dXSMAAAAAAMVSkc7pnj17tkaOHKl//etfyszMPL8jLy8NGjRIL730kksLNEtMTIxiYmKUlZXl7lIAAAAAACVUkUK3zWbT66+/rpdeekm//vqrJKlWrVry8/NzaXFmioyMVGRkpJKTk2Xn0kUAAAAAABMU6fDyHAkJCUpISFBoaKj8/PxkGIar6gIAAAAAoNgrUug+fvy42rVrpxtvvFFdunRRQkKCJGnQoEFcLgwAAAAAgP9XpND9xBNPyGq16tChQ7LZbI723r17a8WKFS4rDkAJlZgoJSScvyUlubsaAAAAwDRFOqd71apVWrlypapVq+bUHhoaqoMHD7qkMAAlT6bVptj1VnmuW+poi+hglaKiJNZWAAAAQAlUpNCdmprqNMOd48SJE/Lx8bniogCUTOm+dm1uHiVrZpokyS8tURGZS6W0NEI3AAAASqQiHV7eunVrLViwwHHfYrEoOztbU6ZMUdu2bV1WHICSJ93XrhT/IKX4BynVFuDucgAAAABTFWmme8qUKWrXrp22bNmijIwMPfXUU/r555914sQJbdiwwdU1AgAAAABQLBVpprt+/frau3evbrvtNt19991KTU1Vz549tX37dtWqVcvVNQIAAAAAUCwVeqY7MzNTd955p2bPnq1nn33WjJoAAAAAACgRCj3TbbVa9eOPP5pRCwAAAAAAJUqRDi9/6KGH9Pbbb7u6FgAAAAAASpQiLaR27tw5zZ07V2vWrFGTJk3k5+fntH3atGkuKQ4AAAAAgOKsUKH7t99+U40aNbRz507dfPPNkqS9e/c69bFYLK6rDgAAAACAYqxQoTs0NFQJCQn6+uuvJUm9e/fWq6++qsqVK5tSHAAAAAAAxVmhzuk2DMPp/vLly5WamurSgq6WmJgYhYWFqVmzZu4uBQAAAABQQhVpIbUcF4fw4iQyMlK7du1SXFycu0sBAAAAAJRQhQrdFosl1znbnMMNAAAAAEDeCnVOt2EY6t+/v3x8fCRJZ8+e1aOPPppr9fKlS5e6rkIAAAAAAIqpQoXufv36Od1/6KGHXFoMAAAAAAAlSaFC97x588yqAwAAAACAEueKFlIDAAAAAAD5I3QDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJim1oTsmJkZhYWFq1qyZu0sBAAAAAJRQpTZ0R0ZGateuXYqLi3N3KQAAAACAEsrL3QUAQKElJUlpaf/ct9kku9199QAAAAD5IHQDKF6SkhTbY6Y8szMdTREdrFJUFMEbAAAA1xxCN4DiJS1NntmZ2l23p1JtAfJLS1RE5tLzM9+EbgAAAFxjCN0Ari0XHzou5Xn4eKotQCn+QVexMAAAAKDwCN0Arh15HDoucfg4AAAAii9CN4Brx0WHjkvi8HEAAAAUa4RuANccDh0HAABASVFqr9MNAAAAAIDZCN0AAAAAAJiEw8sBuF9iovN/AQAAgBKC0A3AbTKtNsWut8pz3VJHW5aHVZlWm/uKAgAAAFyI0A3AbdJ97drcPErWzH+uy51ptSndl1XKAQAAUDIQugG4VbqvnZANAACAEouF1AAAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJN4ubsAACiQxETn/+a3XZJsNslu/+d+UpKUlpb/dgAAAMAkhG4A17RMq02x663yXLfU0ZblYVWm1Zbv9ogOVikq6nywTkpSbI+Z8szOzHs7AAAAYCJCN4BrWrqvXZubR8ma+c9MdabVpnRfe57b/dISFZG59PzMtt0upaXJMztTu+v2VKotIPd2AAAAwESEbgDXvHRfuyNkF2W7JKXaApTiH+Tq0gAAAIBLYiE1AAAAAABMUiJCd48ePVShQgX16tXL3aUAAAAAAOBQIkL38OHDtWDBAneXAQAAAACAkxIRuiMiIuTv7+/uMgAAAAAAcOL20L1+/Xp1795dVatWlcVi0bJly3L1iYmJUY0aNeTr66sWLVpo8+bNV79QAAAAAAAKye2hOzU1VeHh4YqJiclz++LFixUdHa0xY8Zo27ZtCg8PV6dOnXT06NGrXCkAAAAAAIXj9kuGde7cWZ07d853+7Rp0zR48GANGDBAkjR79mx9+eWXmjt3rp5++ulCj5eenq709HTH/eTk5MIXDaD4S0x0vm+zcd1uAAAAuJzbQ/elZGRkaOvWrRo1apSjzcPDQ+3bt9fGjRuLtM9JkyZp3LhxrioRQDGTabUpdr1VnuuWOrVHdLBKUVEEbwAAALjUNR26jx07pqysLFWuXNmpvXLlyvrll18c99u3b68dO3YoNTVV1apV00cffaRbb701z32OGjVK0dHRjvvJycmqXr26OU8AwDUn3deuzc2jZM1Mc7T5pSUqInOplJZG6AYAAIBLXdOhu6DWrFlT4L4+Pj7y8fExsRoA17p0X7vSfQnXAAAAMJ/bF1K7lEqVKsnT01NHjhxxaj9y5IiqVKnipqoAAAAAACiYazp0e3t7q0mTJoqNjXW0ZWdnKzY2Nt/DxwEAAAAAuFa4/fDylJQU7d+/33H/wIEDio+P13XXXacbbrhB0dHR6tevn5o2barmzZtr+vTpSk1NdaxmDgB5ylmd/OJVygEAAICryO2he8uWLWrbtq3jfs4iZ/369dP8+fPVu3dvJSYmavTo0Tp8+LAaNWqkFStW5FpcrbBiYmIUExOjrKysK9oPgGtLXquTZ3lYlWm1ua8oAAAAlFoWwzAMdxfhTsnJybLb7UpKSlK5cuXcXU7eEhK0rs8b2tJkiFL8g9xdDXDN8zmb5LQ6eabVdsmF08qeTtBI/zekIUOkIH7HAAAAcHkFzZJun+kGAFdjdXIAAABcK67phdQAAAAAACjOCN0AAAAAAJiE0A0AAAAAgElKbeiOiYlRWFiYmjVr5u5SAAAAAAAlVKkN3ZGRkdq1a5fi4uLcXQoAAAAAoIQqtaEbAAAAAACzEboBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAk3i5uwAAKJaSkqS0tH/u22yS3e6+egAAAHBNKrWhOyYmRjExMcrKynJ3KQCKm6QkxfaYKc/sTEdTRAerFBVF8AYAAICTUnt4OdfpBlBkaWnyzM7U7ro9taXJEO2u21PKzHSe+QYAAABUime6AeBKpdoClOIf5O4yAAAAcA0rtTPdAAAAAACYjdANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmKTUhu6YmBiFhYWpWbNm7i4FAAAAAFBCldrQzXW6AQAAAABmK7WhGwAAAAAAsxG6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAk3i5uwAAuGYkJv7zs80m2e3uqwUAAAAlQqkN3TExMYqJiVFWVpa7SwHgZplWm2LXW+W5bqmjLaKDVYqKIngDAADgipTa0B0ZGanIyEglJyfLzj+qgVIt3deuzc2jZM1MkyT5pSUqInOplJZG6AYAAMAVKbWhGwAulO5rV7ovARsAAACuxUJqAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJjEy90FAMA1KzGxcO0XSkqS0tKc22w2yW6/8roAAABQbJTa0B0TE6OYmBhlZWW5uxQA15hMq02x663yXLc03z5ZHlZlWm15b0xKUmyPmfLMznRqjuhglaKiCN4AAAClSKkN3ZGRkYqMjFRycrLs/AMYwAXSfe3a3DxK1sy0fPtkWm1K983nuyMtTZ7Zmdpdt6dSbQGSJL+0REVkLj0/+813DgAAQKlRakM3AFxKuq89/1BdQKm2AKX4B7moIgAAABRHLKQGAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYxMvdBQAA3CgpSUpL++e+zSbZ7e6rBwAAoIQptaE7JiZGMTExysrKcncpAOAeSUmK7TFTntmZjqaIDlYpKorgDQAA4CKl9vDyyMhI7dq1S3Fxce4uBQDcIy1NntmZ2l23p7Y0GaLddXtKmZnOM98AAAC4IqV2phsAcF6qLUAp/kHuLgMAAKBEKrUz3QAAAAAAmI3QDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEm83F0AAJQqiYn//GyzSXb7P/eTkqS0tKLv++L9ASj+Lv5e4PccAIqdUhu6Y2JiFBMTo6ysLHeXAqAUyLTaFLveKs91Sx1tER2sUlTU+X9AJyUptsdMeWZnFnkMp/0BKP7y+F7g9xwAip9SG7ojIyMVGRmp5ORk2fkfFwCTpfvatbl5lKyZ52es/NISFZG59PwMlt0upaXJMztTu+v2VKotoND7z7U/AMXfRd8L/J4DQPFUakM3AFxt6b52pfte+h/KqbYApfgHXaWKABQHfC8AQPHGQmoAAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYpESE7i+++EJ16tRRaGio3nrrLXeXAwAAAACAJMnL3QVcqXPnzik6Olpff/217Ha7mjRpoh49eqhixYruLg0AAAAAUMoV+5nuzZs3q169err++utVtmxZde7cWatWrXJ3WQAAAAAAuD90r1+/Xt27d1fVqlVlsVi0bNmyXH1iYmJUo0YN+fr6qkWLFtq8ebNj299//63rr7/ecf/666/XX3/9dTVKBwAAAADgktweulNTUxUeHq6YmJg8ty9evFjR0dEaM2aMtm3bpvDwcHXq1ElHjx69ypUCAAAAAFA4bg/dnTt31sSJE9WjR488t0+bNk2DBw/WgAEDFBYWptmzZ8tms2nu3LmSpKpVqzrNbP/111+qWrXqVakdAAAAAIBLuaYXUsvIyNDWrVs1atQoR5uHh4fat2+vjRs3SpKaN2+unTt36q+//pLdbtfy5cv1/PPP57vP9PR0paenO+4nJyeb9wQAlC6Jic7/NesxhZGUJKWl/XPfZpPsdnPHuJgZY8J1rsZnBNcW3nMA16IS/N10TYfuY8eOKSsrS5UrV3Zqr1y5sn755RdJkpeXl6ZOnaq2bdsqOztbTz311CVXLp80aZLGjRtnat0ASpdMq02x663yXLfU0ZblYVWm1ebSxxRaUpJie8yUZ3amoymig1WKinLd/8TyGONiLh8TrnM1PiO4tvCeA7gWlfDvpms6dBfUXXfdpbvuuqtAfUeNGqXo6GjH/eTkZFWvXt2s0gCUAum+dm1uHiVr5j9/nc202pTum///JIrymEJLS5NndqZ21+2pVFuA/NISFZG59PxfkV31P7CLxriYKWPCda7GZwTXFt5zANeiEv7ddE2H7kqVKsnT01NHjhxxaj9y5IiqVKlSpH36+PjIx8fHFeUBgEO6r73QgbkojymKVFuAUvyDiv0YMA/vX+nDew7gWlRSv5vcvpDapXh7e6tJkyaKjY11tGVnZys2Nla33nqrGysDAAAAAODy3D7TnZKSov379zvuHzhwQPHx8bruuut0ww03KDo6Wv369VPTpk3VvHlzTZ8+XampqRowYIAbqwYAAAAA4PLcHrq3bNmitm3bOu7nnG/dr18/zZ8/X71791ZiYqJGjx6tw4cPq1GjRlqxYkWuxdUKKyYmRjExMcrKyrqi/QAAAAAAkB+3h+6IiAgZhnHJPlFRUYqKinLpuJGRkYqMjFRycrLsJeDkfAAAAADAteeaPqcbAAAAAIDijNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmKTUhu6YmBiFhYWpWbNm7i4FAAAAAFBCldrQHRkZqV27dikuLs7dpQAAAAAASqhSG7oBAAAAADAboRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwSakN3VwyDAAAAABgtlIburlkGAAAAADAbF7uLsDdDMOQJCUnJ7u5kks4fVqp59J1Nv200r393F0NgGuQV/ppJXunS6dPS37//z1x0XdHrj6X214Ql/l+KtI+cfW44jMA85jx/vCeA7gWFdPvppwMmZMp82MxLtejhPvzzz9VvXp1d5cBAAAAACiG/vjjD1WrVi3f7aU+dGdnZ+vvv/+Wv7+/LBaLu8uBiyQnJ6t69er6448/VK5cOXeXA5iKzztKEz7vKE34vKO0KK6fdcMwdPr0aVWtWlUeHvmfuV3qDy/38PC45F8lULyVK1euWP3iAleCzztKEz7vKE34vKO0KI6fdbvdftk+pXYhNQAAAAAAzEboBgAAAADAJIRulEg+Pj4aM2aMfHx83F0KYDo+7yhN+LyjNOHzjtKipH/WS/1CagAAAAAAmIWZbgAAAAAATELoBgAAAADAJIRuAAAAAABMQuhGiRQTE6MaNWrI19dXLVq00ObNm91dEuBykyZNUrNmzeTv76/AwEDdc8892rNnj7vLAkz34osvymKx6PHHH3d3KYAp/vrrLz300EOqWLGiypQpowYNGmjLli3uLgtwuaysLD3//PMKCQlRmTJlVKtWLU2YMEElbdkxQjdKnMWLFys6OlpjxozRtm3bFB4erk6dOuno0aPuLg1wqW+++UaRkZH64YcftHr1amVmZqpjx45KTU11d2mAaeLi4vTGG2+oYcOG7i4FMMXJkyfVqlUrWa1WLV++XLt27dLUqVNVoUIFd5cGuNzkyZM1a9YszZw5U7t379bkyZM1ZcoUvfbaa+4uzaVYvRwlTosWLdSsWTPNnDlTkpSdna3q1avrscce09NPP+3m6gDzJCYmKjAwUN98843atGnj7nIAl0tJSdHNN9+s119/XRMnTlSjRo00ffp0d5cFuNTTTz+tDRs26Ntvv3V3KYDpunXrpsqVK+vtt992tN17770qU6aM3nvvPTdW5lrMdKNEycjI0NatW9W+fXtHm4eHh9q3b6+NGze6sTLAfElJSZKk6667zs2VAOaIjIxU165dnb7jgZLms88+U9OmTXXfffcpMDBQjRs31ptvvunusgBTtGzZUrGxsdq7d68kaceOHfruu+/UuXNnN1fmWl7uLgBwpWPHjikrK0uVK1d2aq9cubJ++eUXN1UFmC87O1uPP/64WrVqpfr167u7HMDlFi1apG3btikuLs7dpQCm+u233zRr1ixFR0frmWeeUVxcnIYNGyZvb2/169fP3eUBLvX0008rOTlZN910kzw9PZWVlaX//e9/evDBB91dmksRugGgBIiMjNTOnTv13XffubsUwOX++OMPDR8+XKtXr5avr6+7ywFMlZ2draZNm+qFF16QJDVu3Fg7d+7U7NmzCd0ocT788EMtXLhQ77//vurVq6f4+Hg9/vjjqlq1aon6vBO6UaJUqlRJnp6eOnLkiFP7kSNHVKVKFTdVBZgrKipKX3zxhdavX69q1aq5uxzA5bZu3aqjR4/q5ptvdrRlZWVp/fr1mjlzptLT0+Xp6enGCgHXCQoKUlhYmFNb3bp1tWTJEjdVBJjnySef1NNPP60HHnhAktSgQQMdPHhQkyZNKlGhm3O6UaJ4e3urSZMmio2NdbRlZ2crNjZWt956qxsrA1zPMAxFRUXpk08+0dq1axUSEuLukgBTtGvXTj/99JPi4+Mdt6ZNm+rBBx9UfHw8gRslSqtWrXJd/nHv3r0KDg52U0WAedLS0uTh4RxJPT09lZ2d7aaKzMFMN0qc6Oho9evXT02bNlXz5s01ffp0paamasCAAe4uDXCpyMhIvf/++/r000/l7++vw4cPS5LsdrvKlCnj5uoA1/H398+1VoGfn58qVqzIGgYocZ544gm1bNlSL7zwgu6//35t3rxZc+bM0Zw5c9xdGuBy3bt31//+9z/dcMMNqlevnrZv365p06Zp4MCB7i7NpbhkGEqkmTNn6qWXXtLhw4fVqFEjvfrqq2rRooW7ywJcymKx5Nk+b9489e/f/+oWA1xlERERXDIMJdYXX3yhUaNGad++fQoJCVF0dLQGDx7s7rIAlzt9+rSef/55ffLJJzp69KiqVq2qPn36aPTo0fL29nZ3eS5D6AYAAAAAwCSc0w0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQBAKbRs2TLVrl1bnp6eevzxx91dzhXp37+/7rnnHneXAQBAngjdAAAUUv/+/WWxWPTiiy86tS9btkwWi8Vxf926dbJYLDp16lSe+xk7dqwaNWqU7zgRERGyWCyyWCzy9fXVjTfeqEmTJskwjCt+DkOGDFGvXr30xx9/aMKECfn22759u3r37q2goCD5+PgoODhY3bp10+eff+6SOlxhxowZmj9/vrvLAAAgT4RuAACKwNfXV5MnT9bJkydNHWfw4MFKSEjQnj17NGrUKI0ePVqzZ8++on2mpKTo6NGj6tSpk6pWrSp/f/88+3366ae65ZZblJKSonfeeUe7d+/WihUr1KNHDz333HNKSkq6ojpcxW63q3z58u4uAwCAPBG6AQAogvbt26tKlSqaNGmSqePYbDZVqVJFwcHBGjBggBo2bKjVq1df8jEnT55U3759VaFCBdlsNnXu3Fn79u2TdH72PSdk33HHHbJYLFq3bl2ufaSmpmrQoEHq2rWrvvzyS3Xs2FE1a9ZU3bp1NWjQIO3YsUN2u12SlJWVpUGDBikkJERlypRRnTp1NGPGDKf9RURE5DqM/Z577lH//v0d919//XWFhobK19dXlStXVq9evRzbPv74YzVo0EBlypRRxYoV1b59e6WmpkrKfXj5ihUrdNttt6l8+fKqWLGiunXrpl9//dWx/ffff5fFYtHSpUvVtm1b2Ww2hYeHa+PGjZd8XQEAKApCNwAAReDp6akXXnhBr732mv7880/TxzMMQ99++61++eUXeXt7X7Jv//79tWXLFn322WfauHGjDMNQly5dlJmZqZYtW2rPnj2SpCVLlighIUEtW7bMtY9Vq1bp+PHjeuqpp/IdJ+dQ+uzsbFWrVk0fffSRdu3apdGjR+uZZ57Rhx9+WODnt2XLFg0bNkzjx4/Xnj17tGLFCrVp00aSlJCQoD59+mjgwIHavXu31q1bp549e+Z7eHtqaqqio6O1ZcsWxcbGysPDQz169FB2drZTv2effVYjR45UfHy8brzxRvXp00fnzp0rcM0AABSEl7sLAACguOrRo4caNWqkMWPG6O233zZljNdff11vvfWWMjIylJmZKV9fXw0bNizf/vv27dNnn32mDRs2OML0woULVb16dS1btkz33XefAgMDJUnXXXedqlSpkud+9u7dK0mqU6eOoy0uLk5t27Z13F+0aJG6desmq9WqcePGOdpDQkK0ceNGffjhh7r//vsL9DwPHTokPz8/devWTf7+/goODlbjxo0lnQ/d586dU8+ePRUcHCxJatCgQb77uvfee53uz507VwEBAdq1a5fq16/vaB85cqS6du0qSRo3bpzq1aun/fv366abbipQzQAAFAQz3QAAXIHJkyc7znc2w4MPPqj4+Hht2LBBnTt31rPPPpvnzHSO3bt3y8vLSy1atHC0VaxYUXXq1LniGhs2bKj4+HjFx8crNTXVaVY4JiZGTZo0UUBAgMqWLas5c+bo0KFDBd53hw4dFBwcrJo1a+rhhx/WwoULlZaWJkkKDw9Xu3bt1KBBA91333168803L3ku/b59+9SnTx/VrFlT5cqVU40aNSQpVz0NGzZ0/BwUFCRJOnr0aIFrBgCgIAjdAABcgTZt2qhTp04aNWqUKfu32+2qXbu2mjVrpg8//FAzZ87UmjVrTBnrQqGhoZLkOBRdknx8fFS7dm3Vrl3bqe+iRYs0cuRIDRo0SKtWrVJ8fLwGDBigjIwMRx8PD49ch4NnZmY6fvb399e2bdv0wQcfKCgoSKNHj1Z4eLhOnTolT09PrV69WsuXL1dYWJhee+011alTRwcOHMiz9u7du+vEiRN68803tWnTJm3atEmSnOqRJKvV6vj5wkPlAQBwJUI3AABX6MUXX9Tnn39u+kJcZcuW1fDhwzVy5Mh8z2euW7euzp075wiaknT8+HHt2bNHYWFhBR6rY8eOuu666zR58uTL9s05lH3o0KFq3Lixateu7bRwmSQFBAQoISHBcT8rK0s7d+506uPl5aX27dtrypQp+vHHH/X7779r7dq1ks6H4latWmncuHHavn27vL299cknn+SqJee5Pvfcc2rXrp3q1q1r+grzAABcCud0AwBwhRo0aKAHH3xQr776ap7bf/rpJ6fLclksFoWHh0uSzpw5o/j4eKf+/v7+qlWrVp77GjJkiCZMmKAlS5Y4re6dIzQ0VHfffbcGDx6sN954Q/7+/nr66ad1/fXX6+677y7wcypbtqzeeust9e7dW127dtWwYcMUGhqqlJQUrVixQtL5xeRyxlywYIFWrlypkJAQvfvuu4qLi1NISIhjf3fccYeio6P15ZdfqlatWpo2bZrT9cu/+OIL/fbbb2rTpo0qVKigr776StnZ2apTp442bdqk2NhYdezYUYGBgdq0aZMSExNVt27dXHVXqFBBFStW1Jw5cxQUFKRDhw7p6aefLvDzBgDA1QjdAAC4wPjx47V48eI8t+Wswp3D09PTcT703r17HQuG5WjXrl2+h5Bfd9116tu3r8aOHauePXvKwyP3QWvz5s3T8OHD1a1bN2VkZKhNmzb66quvnA6nLogePXro+++/1+TJk9W3b1+dOHFCdrtdTZs2dSyiJp3/Q8D27dvVu3dvWSwW9enTR0OHDtXy5csd+xo4cKB27Nihvn37ysvLS0888YTTomzly5fX0qVLNXbsWJ09e1ahoaH64IMPVK9ePe3evVvr16/X9OnTlZycrODgYE2dOlWdO3fOVbOHh4cWLVqkYcOGqX79+qpTp45effVVRUREFOq5AwDgKhYjv+PTAAAAAADAFeGcbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AaAC1gsFo0dO9atNURERCgiIsKp7ciRI+rVq5cqVqwoi8Wi6dOnS5L27dunjh07ym63y2KxaNmyZVe93uKkf//+Klu2rLvLgBvVqFFD/fv3d3cZuAaNHTtWFovF3WUAKIEI3QBKtPnz58tisTjdAgMD1bZtWy1fvtz08fv37+80dtmyZVWzZk316tVLS5YsUXZ2doH288QTT2jlypUaNWqU3n33Xd15552SpH79+umnn37S//73P7377rtq2rSpmU8HeXj99dc1f/58d5dhiot/d/K7rVu3Tr///nu+22+55RZ3P5VCs1gsioqKynPb66+/LovFohYtWuS5ffXq1bJYLBo3blyubQcOHJDNZlOvXr0uOX7Od9eWLVsKX7wb/PjjjxowYIBCQkLk6+ursmXLqlGjRnrqqaf022+/ubs8AHArL3cXAABXw/jx4xUSEiLDMHTkyBHNnz9fXbp00eeff65u3bo5+p05c0ZeXq79avTx8dFbb73l2P/Bgwf1+eefq1evXoqIiNCnn36qcuXKOfqvWrUq1z7Wrl2ru+++WyNHjnSqdePGjXr22WfzDQcw3+uvv65KlSqVyNnTd9991+n+ggULtHr16lztdevW1ZkzZyRJffr0UZcuXZy2BwQEmFvoVbZw4ULVqFFDmzdv1v79+1W7dm2n7R06dNC//vUvTZo0SX369NGNN97o2DZ06FBZrVa9+uqrV7ts07z55pv6z3/+o0qVKunBBx/UTTfdpHPnzmnnzp1asGCBpk+frjNnzsjT09PdpV7Sc889p6efftrdZQAogQjdAEqFzp07O80CDxo0SJUrV9YHH3zgFLp9fX1dPraXl5ceeughp7aJEyfqxRdf1KhRozR48GAtXrzYsc3b2zvXPo4ePary5cs7tSUmJkpSrvYrcfbsWXl7e8vDgwOhoFyf2x9++EGrV6/O1S5Jv//+uyTp5ptvznN7SXHgwAF9//33Wrp0qYYMGaKFCxdqzJgxufq98sorWr58uR599FGtXbtWkrRo0SKtWLFCr776qqpWrXq1SzfF999/r//85z9q1aqVvvjiC/n7+zttnzp1qv73v/+5qbrC8fLycvkfXQFA4vByAKVU+fLlVaZMmVz/wLr4nO6cc/z279+v/v37q3z58rLb7RowYIDS0tKuqIann35aHTt21EcffaS9e/c62i88pzvnEFPDMBQTE+M4XHfs2LEKDg6WJD355JOyWCyqUaOGYx9//fWXBg4cqMqVK8vHx0f16tXT3LlzncZft26dLBaLFi1apOeee07XX3+9bDabkpOTJUmbNm3SnXfeKbvdLpvNpttvv10bNmxw2kdhX5/33ntPzZs3l81mU4UKFdSmTZtcM/vLly9X69at5efnJ39/f3Xt2lU///yzU5/Dhw9rwIABqlatmnx8fBQUFKS7777bEfwu57ffflOnTp3k5+enqlWravz48TIMw6lPdna2pk+frnr16snX11eVK1fWkCFDdPLkSUefGjVq6Oeff9Y333zjeG8iIiJ06tQpeXp6Os1mHjt2TB4eHqpYsaLTWP/5z39UpUoVp7EL8tpLhXufP/zwQ/3vf/9TtWrV5Ovrq3bt2mn//v0Fer3MdvDgQQ0dOlR16tRRmTJlVLFiRd1333253s+c34cNGzYoOjpaAQEB8vPzU48ePRx/hMphGIYmTpyoatWqyWazqW3btrk+R0WxcOFCVahQQV27dlWvXr20cOHCPPsFBgZq8uTJ+vrrr/XOO+/o1KlTeuKJJ9SsWTNFRkZecR05tm/frs6dO6tcuXIqW7as2rVrpx9++MGpT2ZmpsaNG6fQ0FD5+vqqYsWKuu2227R69WpHn6L+To0bN04Wi0ULFy7MFbil83/InDBhgtMs97fffqv77rtPN9xwg3x8fFS9enU98cQTjqMlcuS1voV0/rSdC7/vpPN/0GjSpIn8/f1Vrlw5NWjQQDNmzCjUa5DXOd3z5s3THXfcocDAQPn4+CgsLEyzZs3KVVONGjXUrVs3fffdd2revLl8fX1Vs2ZNLViw4JKvH4DSgT/nASgVkpKSdOzYMRmGoaNHj+q1115TSkpKgWfk7r//foWEhGjSpEnatm2b3nrrLcc/qq/Eww8/rFWrVmn16tVOh6DmaNOmjd599109/PDD6tChg/r27StJatiwocqXL68nnnjCcThvzgJhR44c0S233OI4JzUgIEDLly/XoEGDlJycrMcff9xpjAkTJsjb21sjR45Uenq6vL29tXbtWnXu3FlNmjTRmDFj5OHh4fjH57fffqvmzZsX+vUZN26cxo4dq5YtW2r8+PHy9vbWpk2btHbtWnXs2FHS+cOZ+/Xrp06dOmny5MlKS0vTrFmzdNttt2n79u2Of2jfe++9+vnnn/XYY4+pRo0aOnr0qFavXq1Dhw7l+sf4xbKysnTnnXfqlltu0ZQpU7RixQqNGTNG586d0/jx4x39hgwZovnz52vAgAEaNmyYDhw4oJkzZ2r79u3asGGDrFarpk+frscee0xly5bVs88+K0mqXLmyypcvr/r162v9+vUaNmyYJOm7776TxWLRiRMntGvXLtWrV0/S+QDSunVrx7gFfe0L+z6/+OKL8vDw0MiRI5WUlKQpU6bowQcf1KZNmy75ehVWWlqajh075tRmt9tltVrzfUxcXJy+//57PfDAA6pWrZp+//13zZo1SxEREdq1a5dsNptT/8cee0wVKlTQmDFj9Pvvv2v69OmKiopyOmJk9OjRmjhxorp06aIuXbpo27Zt6tixozIyMq7o+S1cuFA9e/aUt7e3+vTpo1mzZikuLk7NmjXL1feRRx7RO++8o5EjR2rlypVKTEzUV1995bIjSX7++We1bt1a5cqV01NPPSWr1ao33nhDERER+uabbxznnI8dO1aTJk3SI488oubNmys5OVlbtmzRtm3b1KFDB0lF+51KS0vT2rVrFRERoWrVqhW47o8++khpaWn6z3/+o4oVK2rz5s167bXX9Oeff+qjjz4q9OuwevVq9enTR+3atXN85+zevVsbNmzQ8OHDC/wa5GXWrFmqV6+e7rrrLnl5eenzzz/X0KFDlZ2dneuPJ/v371evXr00aNAg9evXT3PnzlX//v3VpEkTx+87gFLKAIASbN68eYakXDcfHx9j/vz5ufpLMsaMGeO4P2bMGEOSMXDgQKd+PXr0MCpWrHjZ8fv162f4+fnlu3379u2GJOOJJ55wtN1+++3G7bffnquuyMhIp7YDBw4YkoyXXnrJqX3QoEFGUFCQcezYMaf2Bx54wLDb7UZaWpphGIbx9ddfG5KMmjVrOtoMwzCys7ON0NBQo1OnTkZ2drajPS0tzQgJCTE6dOjgaCvo67Nv3z7Dw8PD6NGjh5GVleXUN2eM06dPG+XLlzcGDx7stP3w4cOG3W53tJ88eTLP510Q/fr1MyQZjz32mNP4Xbt2Nby9vY3ExETDMAzj22+/NSQZCxcudHr8ihUrcrXXq1cv1/tlGIYRGRlpVK5c2XE/OjraaNOmjREYGGjMmjXLMAzDOH78uGGxWIwZM2Y4ainoa1/Y97lu3bpGenq6o9+MGTMMScZPP/1UsBfv/59Tfv90yPk85nX7+uuvL7nfCz9/OTZu3GhIMhYsWOBoy/l9bt++vdPr88QTTxienp7GqVOnDMMwjKNHjxre3t5G165dnfo988wzhiSjX79+l32uef3ObdmyxZBkrF692jCM8+9XtWrVjOHDh+e7n507dxpWq9WQZDz++OOXHffi5xoXF5dvn3vuucfw9vY2fv31V0fb33//bfj7+xtt2rRxtIWHhxtdu3bNdz9F/Z3asWNHvs/r+PHjRmJiouN24Wcvr/d70qRJhsViMQ4ePOhoy+u70DDO/x4HBwc77g8fPtwoV66cce7cuXxrvdxrYBj/fJ9dKK9aO3XqZNSsWdOpLTg42JBkrF+/3tF29OhRw8fHxxgxYsQlxwVQ8nF4OYBSISYmRqtXr9bq1av13nvvqW3btnrkkUe0dOnSAj3+0UcfdbrfunVrHT9+3HEodlHlzE6fPn36ivaTwzAMLVmyRN27d5dhGDp27Jjj1qlTJyUlJWnbtm1Oj+nXr5/KlCnjuB8fH699+/bpX//6l44fP+54fGpqqtq1a6f169fnWnX9cq/PsmXLlJ2drdGjR+ea5cs5nHP16tU6deqU+vTp41S3p6enWrRooa+//lqSVKZMGXl7e2vdunVOh3oXxoULz+XMFGdkZGjNmjWSzs/E2e12dejQwamWJk2aqGzZso5aLqV169Y6cuSI9uzZI+n8jHabNm3UunVrffvtt5LOz34bhuGY6S7oa1+U93nAgAFO6wXkjOnqlaX//e9/O37Xcm7h4eGXfMyFn7/MzEwdP35ctWvXVvny5XM9j5wxLjwMuHXr1srKytLBgwclSWvWrFFGRoYee+wxp34Xz/4X1sKFC1W5cmW1bdtW0vnPTu/evbVo0SJlZWXl+Zhy5co5XvecIzpcISsrS6tWrdI999yjmjVrOtqDgoL0r3/9S999953j9698+fL6+eeftW/fvjz3VdTfqZz953UZvpo1ayogIMBx++yzz5zGy5Gamqpjx46pZcuWMgxD27dvL/D4OcqXL6/U1FSnQ8Xz6nOp1yA/F9aac8TU7bffrt9++01JSUlOfcPCwpyOWgkICFCdOnVYvR0Ah5cDKB2aN2/utJBanz591LhxY0VFRalbt255Ll52oRtuuMHpfoUKFSRJJ0+edFp5vLBSUlIkKc9zIYsiMTFRp06d0pw5czRnzpw8+xw9etTpfkhIiNP9nH+U9uvXL99xkpKSHK+BdPnX59dff5WHh4fCwsLy3WfOuHfccUee23NeZx8fH02ePFkjRoxQ5cqVdcstt6hbt27q27dvrnOj8+Lh4eEUUiQ5Du3POX913759SkpKUmBgYJ77uPg1zEvOP76//fZbVatWTdu3b9fEiRMVEBCgl19+2bGtXLlyjlBa0Nc+MzOz0O/zpd4jVwoNDVX79u0L9ZgzZ85o0qRJmjdvnv766y+nc94vDjbS5Z9LTvgODQ116hcQEOD0uS2MrKwsLVq0SG3bttWBAwcc7S1atNDUqVMVGxubZ6iOioqSh4eHgoODNWLECLVv3/6Sh9oXVGJiotLS0lSnTp1c2+rWravs7Gz98ccfqlevnsaPH6+7775bN954o+rXr68777xTDz/8sBo2bCip6L9TOd9bOd9jF/r000+VmZmpHTt2OF11QZIOHTqk0aNH67PPPsv1+cvr/b6coUOH6sMPP1Tnzp11/fXXq2PHjrr//vsdl1aUdNnXID8bNmzQmDFjtHHjxlzrVCQlJclutzvuX/y5lM5/Nl39Owag+CF0AyiVPDw81LZtW82YMUP79u277Pl2+V3qxrho8a3C2rlzpyTluuRQUeXMQD/00EP5BreL/5F54UzOhft46aWX1KhRozz3cfHMliten5xx33333Tz/oX/honePP/64unfvrmXLlmnlypV6/vnnNWnSJK1du1aNGzcu8JiXqiUwMDDfRbIKcgmsqlWrKiQkROvXr1eNGjVkGIZuvfVWBQQEaPjw4Tp48KC+/fZbtWzZ0jH7X9DX/vjx45IK9z6b9Rl2hccee0zz5s3T448/rltvvVV2u10Wi0UPPPBAnteyd8dzWbt2rRISErRo0SItWrQo1/aFCxfmCt1Lly7VZ599punTpys0NFRdu3bVSy+9pGeeeca0OvPSpk0b/frrr/r000+1atUqvfXWW3rllVc0e/ZsPfLII5KK9jtVu3ZteXl5Ob7HLnT77bdLUq7FKrOystShQwedOHFC//3vf3XTTTfJz89Pf/31l/r37+/0fucsInmxi48qCAwMVHx8vFauXKnly5dr+fLlmjdvnvr27at33nmnwK/BxX799Ve1a9dON910k6ZNm6bq1avL29tbX331lV555ZVcn81r+XcMgHsRugGUWufOnZOU9yzN1fLuu+/KYrFcciGfwggICJC/v7+ysrIKPduYo1atWpLOzywXdR957TM7O1u7du3KN0zmjBsYGFigcWvVqqURI0ZoxIgR2rdvnxo1aqSpU6fqvffeu+TjsrOz9dtvvzktXJezenzOglG1atXSmjVr1KpVq1x/lLjYxasdX6h169Zav369QkJC1KhRI/n7+ys8PFx2u10rVqzQtm3bNG7cOKfnJF3+tXfF+3wt+fjjj9WvXz9NnTrV0Xb27FmdOnWqSPvLWdl/3759Tkc1JCYmFnnWceHChQoMDFRMTEyubUuXLtUnn3yi2bNnOz4vp0+f1rBhw3TzzTcrKipKnp6euvfeezVx4kT16dMn1xEmhRUQECCbzeY4feFCv/zyizw8PFS9enVH23XXXacBAwZowIABSklJUZs2bTR27FinwFnY3yk/Pz/Hom1//fWXrr/++svW/dNPP2nv3r165513HAtDSsrz0PAKFSrkeWh2zpEMF/L29lb37t3VvXt3ZWdna+jQoXrjjTf0/PPPO/6oWZDX4EKff/650tPT9dlnnznNYhfk9BIAuBDndAMolTIzM7Vq1Sp5e3urbt26bqnhxRdf1KpVq9S7d+9ch8EWVc4/7JcsWZLn7NPFl1XKS5MmTVSrVi29/PLLef5BoiD7uNg999wjDw8PjR8/PtfsUM4sUKdOnVSuXDm98MILyszMzHfctLQ0nT171mlbrVq15O/vr/T09ALVM3PmTKfxZ86cKavVqnbt2kk6vxp7VlaWJkyYkOux586dcwqDfn5++YbD1q1b6/fff9fixYsdh5t7eHioZcuWmjZtmjIzM53OAS3oa++K9/la4unpmWs28LXXXsv3POnLyTmE+7XXXnPa7/Tp04u0vzNnzmjp0qXq1q2bevXqlesWFRWl06dPO523/NxzzykhIUFvvPGGYwZ0xowZ8vT0dFpToKg8PT3VsWNHffrpp06X9Tpy5Ijef/993XbbbY5TMnKOjMhRtmxZ1a5d2/H7ciW/U6NHj1ZWVpYeeuihPD+zF7+vOa/Fhe2GYThd3uvCGn755Renz/OOHTtyXT7v4ufn4eHhONIjp/7LvQZ5yavWpKQkzZs3L9/HAEBemOkGUCosX75cv/zyi6Tz57q+//772rdvn55++ukrOie7IM6dO+eYKTp79qwOHjyozz77TD/++KPatm2b7zm5RfXiiy/q66+/VosWLTR48GCFhYXpxIkT2rZtm9asWaMTJ05c8vEeHh5666231LlzZ9WrV08DBgzQ9ddfr7/++ktff/21ypUrp88//7xQNdWuXVvPPvusJkyYoNatW6tnz57y8fFRXFycqlatqkmTJqlcuXKaNWuWHn74Yd1888164IEHFBAQoEOHDunLL79Uq1atNHPmTO3du1ft2rXT/fffr7CwMHl5eemTTz7RkSNH9MADD1y2Fl9fX61YsUL9+vVTixYttHz5cn355Zd65plnHIeN33777RoyZIgmTZqk+Ph4dezYUVarVfv27dNHH32kGTNmqFevXpLOB+VZs2Zp4sSJql27tgIDAx3npecE6j179uiFF15w1NCmTRstX75cPj4+TpeaKsxrf6Xv87WkW7duevfdd2W32xUWFqaNGzdqzZo1qlixYpH2FxAQoJEjR2rSpEnq1q2bunTpou3bt2v58uWqVKlSoff32Wef6fTp07rrrrvy3H7LLbcoICBACxcuVO/evbV161bFxMQoMjLSaS2J66+/XuPHj1d0dLSWLFmie++997Jjz507VytWrMjVPnz4cE2cOFGrV6/WbbfdpqFDh8rLy0tvvPGG0tPTNWXKFEffsLAwRUREqEmTJrruuuu0ZcsWffzxx47wfyW/U61bt9bMmTP12GOPKTQ0VA8++KBuuukmZWRkaO/evVq4cKG8vb0dp4zcdNNNqlWrlkaOHKm//vpL5cqV05IlS/I8AmHgwIGaNm2aOnXqpEGDBuno0aOaPXu26tWr57SI5SOPPKITJ07ojjvuULVq1XTw4EG99tpratSokeOPqpd7DfLSsWNHxwz6kCFDlJKSojfffFOBgYFKSEi45OsCAE6u5lLpAHC15XXJMF9fX6NRo0bGrFmznC4nZBj5XzIs51JSF+/3wIEDlxw/5xJVOTebzWbUqFHDuPfee42PP/441+WzDOPKLxlmGIZx5MgRIzIy0qhevbphtVqNKlWqGO3atTPmzJnj6JNzKamPPvooz9q3b99u9OzZ06hYsaLh4+NjBAcHG/fff78RGxtb5Ndn7ty5RuPGjQ0fHx+jQoUKxu233+64/NKFdXXq1Mmw2+2Gr6+vUatWLaN///7Gli1bDMMwjGPHjhmRkZHGTTfdZPj5+Rl2u91o0aKF8eGHH+b5PC6Ucwm3X3/91ejYsaNhs9mMypUrG2PGjMnzvZgzZ47RpEkTo0yZMoa/v7/RoEED46mnnjL+/vtvR5/Dhw8bXbt2Nfz9/Q1Jud67wMBAQ5Jx5MgRR9t3331nSDJat26dZ50Fee0N48re55zPz7x58y77uuUoyCXDinIpt5MnTxoDBgwwKlWqZJQtW9bo1KmT8csvvxjBwcFOl/fK7zJaOc/xwkuTZWVlGePGjTOCgoKMMmXKGBEREcbOnTtz7TMv2dnZhiRj2LBhhmEYRvfu3Q1fX18jNTU138f079/fsFqtxrFjx4ybb77ZqFq1qpGUlJSr37lz54xGjRoZ1apVM06fPp3v/vK73GHO7Y8//jAMwzC2bdtmdOrUyShbtqxhs9mMtm3bGt9//73TviZOnGg0b97cKF++vFGmTBnjpptuMv73v/8ZGRkZhmFc2e9Uju3btxt9+/Y1brjhBsPb29vw8/MzGjZsaIwYMcLYv3+/U99du3YZ7du3N8qWLWtUqlTJGDx4sOPyYxd/Ht977z2jZs2ahre3t9GoUSNj5cqVuS4Z9vHHHxsdO3Y0AgMDDW9vb+OGG24whgwZYiQkJBT4NTCMvC8Z9tlnnxkNGzY0fH19jRo1ahiTJ0825s6dm+v7LTg4OM9LkuV32TMApYvFMFjdAQAAIEdycrLsdruee+65PE8xAACgMDinGwAA4AJxcXGSdMlL3AEAUFDMdAMAAEj68ccftWbNGk2bNk1nz57Vb7/9ZvqaDwCAko+ZbgAAAJ2/9NczzzyjGjVqaPny5QRuAIBLMNMNAAAAAIBJmOkGAAAAAMAkhG4AAAAAAEzi5e4C3C07O1t///23/P39ZbFY3F0OAAAAAKAYMAxDp0+fVtWqVeXhkf98dqkP3X///beqV6/u7jIAAAAAAMXQH3/8oWrVquW7vdSHbn9/f0nnXyhWKQUAAAAAFERycrKqV6/uyJT5KfWhO+eQ8nLlyhG6AQAAAACFcrnTlFlIDQAAAAAAk7g0dGdkZGjPnj06d+6cK3cLAAAAAECx5JLQnZaWpkGDBslms6levXo6dOiQJOmxxx7Tiy++6IohAAAAAAAodlwSukeNGqUdO3Zo3bp18vX1dbS3b99eixcvdsUQAAAAAAAUOy5ZSG3ZsmVavHixbrnlFqeTyOvVq6dff/3VFUMAAAAAAFDsuCR0JyYmKjAwMFd7amrqZVdyAy6n+wfdne5/3udzN1UCAAAAAIXjksPLmzZtqi+//NJxPydov/XWW7r11ltdMQQAAAAAAMWOS2a6X3jhBXXu3Fm7du3SuXPnNGPGDO3atUvff/+9vvnmG1cMAQAAAABAseOSme7bbrtN8fHxOnfunBo0aKBVq1YpMDBQGzduVJMmTVwxBAAAAAAAxY5LZrolqVatWnrzzTddtTsAAAAAAIo9l8x0f/XVV1q5cmWu9pUrV2r58uWuGAIAAAAAgGLHJaH76aefVlZWVq52wzD09NNPu2IIAAAAAACKHZeE7n379iksLCxX+0033aT9+/e7YggAAAAAAIodl4Ruu92u3377LVf7/v375efn54ohAAAAAAAodlwSuu+++249/vjj+vXXXx1t+/fv14gRI3TXXXe5YggAAAAAAIodl4TuKVOmyM/PTzfddJNCQkIUEhKiunXrqmLFinr55ZddMQQAAAAAAMWOSy4ZZrfb9f3332v16tXasWOHypQpo4YNG6pNmzau2D0AAAAAAMWSy67TbbFY1LFjR3Xs2NFVuwQAAAAAoFhzWeiOjY1VbGysjh49quzsbKdtc+fOddUwAAAAAAAUGy4J3ePGjdP48ePVtGlTBQUFyWKxuGK3AAAAAAAUay4J3bNnz9b8+fP18MMPu2J3AAAAAACUCC5ZvTwjI0MtW7Z0xa4AAAAAACgxXBK6H3nkEb3//vuu2BUAAAAAACWGSw4vP3v2rObMmaM1a9aoYcOGslqtTtunTZvmimEAAAAAAChWXBK6f/zxRzVq1EiStHPnTqdtLKoGAAAAACitXBK6v/76a1fsBgAAAACAEsUl53Tn2L9/v1auXKkzZ85IkgzDcOXuAQAAAAAoVlwSuo8fP6527drpxhtvVJcuXZSQkCBJGjRokEaMGOGKIQAAAAAAKHZcErqfeOIJWa1WHTp0SDabzdHeu3dvrVixwhVDAAAAAABQ7LgkdK9atUqTJ09WtWrVnNpDQ0N18OBBVwyRp0mTJqlZs2by9/dXYGCg7rnnHu3Zs8e08QAAAAAAKAyXhO7U1FSnGe4cJ06ckI+PjyuGyNM333yjyMhI/fDDD1q9erUyMzPVsWNHpaammjYmAAAAAAAF5ZLVy1u3bq0FCxZowoQJks5fJiw7O1tTpkxR27ZtXTFEni4+dH3+/PkKDAzU1q1b1aZNG9PGBQAAAACgIFwSuqdMmaJ27dppy5YtysjI0FNPPaWff/5ZJ06c0IYNG1wxRIEkJSVJkq677rqrNiYAAAAAAPlxSeiuX7++9u7dq5kzZ8rf318pKSnq2bOnIiMjFRQU5IohLis7O1uPP/64WrVqpfr16+fbLz09Xenp6Y77ycnJV6M8AAAAAEApdMWhOzMzU3feeadmz56tZ5991hU1FUlkZKR27typ77777pL9Jk2apHHjxl2lqszT/YPuudo+7/O5GypxdnFd10JNF7tWXzsAAAAAJc8VL6RmtVr1448/uqKWIouKitIXX3yhr7/+OtcK6hcbNWqUkpKSHLc//vjjKlUJAAAAAChtXLJ6+UMPPaS3337bFbsqFMMwFBUVpU8++URr165VSEjIZR/j4+OjcuXKOd0AAAAAADCDS87pPnfunObOnas1a9aoSZMm8vPzc9o+bdo0VwyTS2RkpN5//319+umn8vf31+HDhyVJdrtdZcqUMWVMAAAAAAAKyiWhe+fOnbr55pslSXv37nXaZrFYXDFEnmbNmiVJioiIcGqfN2+e+vfvb9q4AAAAAAAUhEtC99dff+2K3RSaYRhuGRcAAAAAgIJwyTndOfbv36+VK1fqzJkzkgjFAAAAAIDSzSWh+/jx42rXrp1uvPFGdenSRQkJCZKkQYMGacSIEa4YAgAAAACAYsclofuJJ56Q1WrVoUOHZLPZHO29e/fWihUrXDEEAAAAAADFjkvO6V61apVWrlyZ6xrZoaGhOnjwoCuGAAAAAACg2HHJTHdqaqrTDHeOEydOyMfHxxVDAAAAAABQ7LgkdLdu3VoLFixw3LdYLMrOztaUKVPUtm1bVwwBAAAAAECx45LDy6dMmaJ27dppy5YtysjI0FNPPaWff/5ZJ06c0IYNG1wxBAAAAAAAxY5LZrrr16+vvXv36rbbbtPdd9+t1NRU9ezZU9u3b1etWrVcMQQAAAAAAMVOkWe6e/bsqfnz56tcuXJasGCBevfurWeffdaVtQEAAAAAUKwVeab7iy++UGpqqiRpwIABSkpKcllRAAAAAACUBEWe6b7ppps0atQotW3bVoZh6MMPP1S5cuXy7Nu3b98iFwgAAAAAQHFV5NA9a9YsjRgxQl9++aUsFouee+45WSyWXP0sFguhGwAAAABQKhU5dLdq1Uo//PCDJMnDw0N79+5VYGCgywoDAAAAAKC4K/I53T179lRycrIkad68efL393dZUQAAAAAAlAQuWUht4MCBOn36tMuKAgAAAACgJGAhNQAAAAAATFLk0D179mxFR0ezkBoAAAAAAPkocuhu2bIlC6kBAAAAAHAJRT6n+0IHDhxQQECAK3YFAAAAAECJUeSZ7h9//FH169eXh4eHkpKS9NNPP+Xbt2HDhkUdBgAAAACAYqvIobtRo0Y6fPiwAgMD1ahRI1ksFhmG4diec99isSgrK8slxQIAAAAAUJwUOXRfeEj5gQMHXFYQAAAAAAAlRZFDd3BwcJ4/AwAAAACA84ocui+0du1aLV26VL///rssFotCQkLUq1cvtWnTxhW7h0m6f9Dd6f7nfT53UyWuVVKfV1Fc7rXgtQIAAADMdcWrlz/66KNq3769PvjgAx0/flyJiYlauHCh2rZtq8cee8wVNQIAAAAAUCxdUej+5JNPNG/ePM2dO1fHjh3Txo0b9cMPPygxMVFvvvmm5syZo88++8xVtQIAAAAAUKxcUeieN2+eoqOj1b9/f1ksln926uGhgQMH6vHHH9fbb799xUUCAAAAAFAcXVHo3rZtm3r06JHv9p49e2rr1q1XMgQAAAAAAMXWFYXuY8eOqVq1avlur1atmo4fP34lQwAAAAAAUGxdUejOyMiQ1WrNd7uXl5cyMjKuZAgAAAAAAIqtK75k2PPPPy+bzZbntrS0tCvdPQAAAAAAxdYVhe42bdpoz549l+0DAAAAAEBpdEWhe926dS4qAwAAAACAkueKzukGAAAAAAD5I3QDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJrni63TnOHXqlDZv3qyjR48qOzvbaVvfvn1dNQwAAAAAAMWGS0L3559/rgcffFApKSkqV66cLBaLY5vFYiF0AwAAAABKJZccXj5ixAgNHDhQKSkpOnXqlE6ePOm4nThxwhVDAAAAAABQ7LgkdP/1118aNmyYbDabK3YHAAAAAECJ4JLQ3alTJ23ZssUVuwIAAAAAoMRwyTndXbt21ZNPPqldu3apQYMGslqtTtvvuusuVwwDAAAAAECx4pLQPXjwYEnS+PHjc22zWCzKyspyxTAAAAAAABQrLgndF18iDAAAAAAAuOicbgAAAAAAkFuRZ7pfffVV/fvf/5avr69effXVS/YdNmxYUYcBAAAAAKDYKnLofuWVV/Tggw/K19dXr7zySr79LBaL6aE7JiZGL730kg4fPqzw8HC99tprat68ualjAgAAAABwOUUO3QcOHMjz56tt8eLFio6O1uzZs9WiRQtNnz5dnTp10p49exQYGOi2ugAAAAAAKPbndE+bNk2DBw/WgAEDFBYWptmzZ8tms2nu3LnuLg0AAAAAUMpd8erl+/bt048//qibb75ZISEh+vLLLzV58mSdOXNG99xzj5555hlZLBZX1JpLRkaGtm7dqlGjRjnaPDw81L59e23cuLFQ+0pNTZWnp2eudk9PT/n6+jr1y4+Hh4fKlClTpL5paWkyDCPPvhaLRTabzanvubPn8nwOF/c9c+ZMvqvLnzt7Tl6+XgXqK0l+fn6On8+ePZvnpeBy6rpwv/n1zWGz2RyfkfT0dJ075/zcLnyunj7/vEd59b2wv6e3pywe5/ebkZGhzMzMXPvLkZ2dLQ8Pj1x98+Lr6+v4rBSmb2ZmpjIyMvLt6+PjIy8vr0L3PXfunNLT0/Psd+7sOXl4ecjDyyPPvhe/FpmZmbJarZKkrKwsnT17Nt8arFarvL29C903OztbZ86ccUlfLy8v+fj4SJIMw1BaWppL+hbm9/5a/Y4oaN/C/N674juiKH0v9x1R1L5lypQp8O99YfoWp+8ISfL29nb83hemL98RfEdIfEcUpS/fEefxHVH4vnxHFK2vmd8RBWZcgaVLlxpeXl6Gt7e34ePjY7zzzjuGr6+vceeddxpdu3Y1vLy8jBdffPFKhrikv/76y5BkfP/9907tTz75pNG8efM8H3P27FkjKSnJcfvjjz8MSfneunTp4vR4m82Wb9/bb7/dqW+lSpXy7du0aVOnvsHBwfn2DQsLc+obFhaWb9/g4GCnvk2bNs23r7e/t9Ht/W6O2+23355vX5vN5rTfLl26XPJ1y9mnYRhGr169Ltk3JSXFsd9+/fpdsm+H2R0cfYcOHXrJvnfMuMNRw8iRIy/Zd+fOnY79jvm/9u49qqoy/+P45wCCmEdUUtHREC95RfCWM/rLwbxl4qSmEqMp5nLZpBkxTmEXidQIp8yUNM2GbqaRmbeSyaHMMkexxMElIk6a97AbCpUg5/z+YHFGAo7g2dsT8H6txVrsvb88z/ecs8/j+rqf/ey4OKexe/fudcQuWrTIaezHH3/siE1KSnIau3XrVkdscnKy09iUlBRHbEpKitPYkBkhjs9j69atTmOTkpIc7X788cdOYxctWuSI3bt3r9PYuLg4R+zBgwedxs6ZM8cRe+zYMaex999/vyM2NzfXaeyUKVMcsfn5+U5jx40bV+Z8dxZbm8eIG2+8sUyskWPElYwcI3Jzcx2xVxsjjh075oity2NEcnKyI5YxogRjxP8wRpRgjCjBGFGCMeJ/6voYkZeXZ5dkz8vLszvj0pXuhQsX6uGHH9aCBQv06quv6r777lNCQoKio6MlSatWrdLzzz+vRx55xJVuDJWQkKD4+Hh3p1Fto9aOcvx+Iu9EpXG5BbmO2C2RW5y22cinUZmYsJVhVc5h35l9TmOv1ndl0o6lOT2+ZuwaRx6ZOZlOY1/50ytq27atRq0dpUNZh5zGzvxgpqz/sUqSsjOzq5Hxb1/076MVFRklSXr//fedxr607yWlrk2VJH176FuzUwMAAABqPYvdXsncgSqwWq3KyMhQ+/btZbPZ5O3trYyMDHXv3l2SdPz4cXXt2tXp9AtXFBYWqkGDBlq/fr1Gjx7t2D9lyhT9+OOP2rRpU7m/uXTpUplpMRcuXFCbNm105swZNWrUqFz8b2XKR8SmCMd28aVivTP+nXJx41LGyWKxOKZgb4ncUmYax7iUcWXi109YX60pH3dvvvt/ORQWy24rn+/6CeslXfuUjztev0P24rLtlrZZGvundX8qyaGoWPZie5njVyqd6jVq7SjZLttku2wr116piI0Rjqnotss2pYxNqTTf3+q0sF9/vlLJa63OtLAJGyY4pqLbbXa9PfrtSmOZFlb9WKaFXVssU0dLMHW0+rGMESUYI64tljGiBGNE9WMZI/6nto8R+fn58vPzU15eXoW1ZCmXrnQXFBTIai25Olj6wV75Ifj6+jr9YrrK29tbvXv3VlpamqPottlsSktL06xZsyr8Gx8fH8cX5ko33HBDmQ+vMlWJuZbYK9+3q/H08ayw7Svvoy515Zft18d/3UZ17kvw9C5//3tFbUoqM5Bctd16nlK9q7d5ZWxV3ucr72uuKL604C6Nrepn5+3t7RjYr6ZevXqOf4iMjPXy8ir5qeDz//XrKI2tTOl7JJW8J1V9Hzw9Kz4nK+zDo+rvb3ViLZaq51udWMm8771ZY0R1Yqvzva9ObHW+99WJrWwMdzW2Ot9ls2LNHiOMjq3O954xwvxYxogSjBHVj2WMKMEYcW2xjBFV41LRbbFYyiyS9uvt6yEmJkZTpkxRnz59dMstt2jJkiUqKCjQ1KlTr2seAAAAAAD8mktFt91u18033+wotPPz89WzZ0/H9BoXZq5XWUREhM6fP6958+bp3LlzCg0NVWpqqlq0aGF63wAAAAAAOONS0Z2cnGxUHi6ZNWtWpdPJAQAAAABwF5eK7ilTphiVBwAAAAAAtY7H1UMAAAAAAMC1oOgGAAAAAMAkFN0AAAAAAJiEohsAAAAAAJO4VHT/8ssvV43JyclxpQsAAAAAAGosl4ru0NBQ7dmzp9LjixcvVmhoqCtdAAAAAABQY7lUdA8dOlS33nqr5s6dq6KiIsf+nJwcDRgwQAkJCVq9erXLSQIAAAAAUBO5VHQvW7ZM27Zt09q1a9WrVy/t27dPzz//vEJCQnTjjTcqMzNTkZGRRuUKAAAAAECN4uVqA4MHD1ZmZqYmTZqkfv36qUGDBlq5cqXuueceI/IDAAAAAKDGMmT18rVr1+rjjz9Wv379VFRUpJ07dyo/P9+IpgEAAAAAqLFcKrpPnz6t4cOH65FHHtHSpUv1+eefa8+ePUpPT1e3bt2UlpZmVJ4AAAAAANQ4LhXd3bt3l8ViUWZmpqKioiRJISEhSk9P1z333KMRI0boL3/5ixF5AgAAAABQ47hUdCckJCg1NVWtW7cus79evXpasGCBdu3apZ07d7qUIAAAAAAANZVLRfd9993n9Hjfvn21Y8cOV7oAAAAAAKDGMmQhtYp8+OGHmjBhgm666SazugAAAAAA4DfN0KL766+/VlxcnNq2bavx48fLw8NDr7/+upFdAAAAAABQY7j8nO7CwkJt2LBBq1ev1q5duzRkyBCdOnVK+/fvV3BwsBE5AgAAAABQI7l0pfuBBx5Qq1at9MILL2jMmDE6deqUtmzZIovFIk9PT6NyBAAAAACgRnLpSveKFSv0yCOPKDY2Vlar1aicAAAAAACoFVy60v3GG29o7969atmypSIiIrR161YVFxcblRsAAAAAADWaS0V3ZGSktm/frszMTHXu3FkzZ85UQECAbDabDh06ZFSOAAAAAADUSIasXh4UFKT4+HgdP35cb775pu666y5NmjRJrVu31uzZs43oAgAAAACAGsdit9vtZjT83Xff6Y033lBycrIOHDhgRheGuHDhgvz8/JSXl6dGjRq5Ox1Uwai1o8psb4ncYmg8AAAAAFxNVWtJQ5/TfSV/f39FR0f/pgtuAAAAAADM5NLq5T179pTFYnHegZeXAgICNHToUM2YMUPe3t6udAkAAAAAQI3hUtE9evToq8bYbDbl5uZqwYIFysrK0vLly13pEgAAAACAGsOlojsuLq7KsZGRkZowYQJFNwAAAACgzjDtnu5f69Wrl/785z9fr+4AAAAAAHC761Z0N2zYUIsXL75e3QEAAAAA4HbXregGAAAAAKCuoegGAAAAAMAkhhfdp06dks1mM7pZAAAAAABqHMOL7q5du+r48eNGNwsAAAAAQI1jeNFtt9uNbhIAAAAAgBqJe7oBAAAAADCJ4UX3o48+qqZNmxrdLAAAAAAANY6X0Q3OnTvX6CYBAAAAAKiRmF4OAAAAAIBJKLoBAAAAADAJRTcAAAAAACah6AYAAAAAwCQuFd2TJ0/WxYsXHdsHDhxQUVGRy0kBAAAAAFAbuFR0r1mzRj///LNj+9Zbb9XJkyddTgoAAAAAgNrApaLbbrc73QYAAAAAoC7jnm4AAAAAAEzi5WoDhw4d0rlz5ySVXOk+fPiw8vPzy8T06NHD1W4AAAAAAKhxXC66Bw8eXGZaeXh4uCTJYrHIbrfLYrGouLjY1W4AAAAAAKhxXCq6jx07ZlQe1Xb8+HHNnz9fH330kc6dO6dWrVpp0qRJeuyxx+Tt7e22vAAAAAAAKOVS0f3aa69pzpw5atCggVH5VNnhw4dls9m0cuVKdejQQQcPHtT06dNVUFCgZ5999rrnAwAAAADAr7lUdMfHx+u+++5zS9F9++236/bbb3dst2vXTtnZ2VqxYgVFNwAAAADgN8Glovu39oiwvLw8NW3a1GnMpUuXdOnSJcf2hQsXzE4LAAAAAFBHubyQmsViMSIPlx09elTLli276lXuhIQExcfHX6esYIYtkVtMjQcAAAAAo1jsLlyu9vDwkJ+f31UL7++//77KbcbGxioxMdFpTFZWljp37uzYPn36tP74xz8qLCxMq1evdvq3FV3pbtOmjfLy8tSoUaMq5wkAAAAAqLsuXLggPz+/q9aSLl/pjo+Pl5+fn6vNOPz1r39VVFSU05h27do5fj9z5owGDRqk/v37a9WqVVdt38fHRz4+Pq6mCQAAAADAVblcdN99991q3ry5EblIkpo1a6ZmzZpVKfb06dMaNGiQevfureTkZHl4eBiWBwAAAAAArnKp6Hbn/dynT59WWFiYAgMD9eyzz+r8+fOOYwEBAW7LCwAAAACAUjV29fLt27fr6NGjOnr0qFq3bl3m2G9tVXUAAAAAQN3k0kJqtUFVb34HAAAAAKDUdVtIraYr/T8HntcNAAAAAKiq0hryatex63zRffHiRUlSmzZt3JwJAAAAAKCmuXjxotMnetX56eU2m01nzpyR1Wp168JwMFbp89dPnjzJbQOo9TjfUZdwvqMu4XxHXVFTz3W73a6LFy+qVatWTp+kVeevdHt4eJRbiA21R6NGjWrUFxdwBec76hLOd9QlnO+oK2riue7sCncpHmwNAAAAAIBJKLoBAAAAADAJRTdqJR8fH8XFxcnHx8fdqQCm43xHXcL5jrqE8x11RW0/1+v8QmoAAAAAAJiFK90AAAAAAJiEohsAAAAAAJNQdAMAAAAAYBKKbtRKL774otq2bav69eurX79+2rt3r7tTAgyXkJCgvn37ymq1qnnz5ho9erSys7PdnRZgumeeeUYWi0XR0dHuTgUwxenTpzVp0iT5+/vL19dXwcHB2rdvn7vTAgxXXFysJ554QkFBQfL19VX79u01f/581bZlxyi6Ueu8/fbbiomJUVxcnL788kuFhIRo+PDhys3NdXdqgKE++eQTzZw5U//+97+1fft2FRUVadiwYSooKHB3aoBp0tPTtXLlSvXo0cPdqQCm+OGHHzRgwADVq1dP27Zt06FDh/Tcc8+pSZMm7k4NMFxiYqJWrFihpKQkZWVlKTExUYsWLdKyZcvcnZqhWL0ctU6/fv3Ut29fJSUlSZJsNpvatGmjBx54QLGxsW7ODjDP+fPn1bx5c33yyScaOHCgu9MBDJefn69evXpp+fLlWrBggUJDQ7VkyRJ3pwUYKjY2Vrt27dKnn37q7lQA04WHh6tFixZ65ZVXHPvuuusu+fr66s0333RjZsbiSjdqlcLCQn3xxRcaMmSIY5+Hh4eGDBmi3bt3uzEzwHx5eXmSpKZNm7o5E8AcM2fO1MiRI8uM8UBts3nzZvXp00fjx49X8+bN1bNnT7388svuTgswRf/+/ZWWlqYjR45Ikg4cOKDPPvtMI0aMcHNmxvJydwKAkb799lsVFxerRYsWZfa3aNFChw8fdlNWgPlsNpuio6M1YMAAde/e3d3pAIZbt26dvvzyS6Wnp7s7FcBUX331lVasWKGYmBg9+uijSk9P1+zZs+Xt7a0pU6a4Oz3AULGxsbpw4YI6d+4sT09PFRcXa+HChZo4caK7UzMURTcA1AIzZ87UwYMH9dlnn7k7FcBwJ0+e1IMPPqjt27erfv367k4HMJXNZlOfPn309NNPS5J69uypgwcP6qWXXqLoRq2TkpKiNWvW6K233lK3bt2UkZGh6OhotWrVqlad7xTdqFVuvPFGeXp66ptvvimz/5tvvlFAQICbsgLMNWvWLG3dulU7d+5U69at3Z0OYLgvvvhCubm56tWrl2NfcXGxdu7cqaSkJF26dEmenp5uzBAwTsuWLdW1a9cy+7p06aJ3333XTRkB5vnb3/6m2NhY3X333ZKk4OBgff3110pISKhVRTf3dKNW8fb2Vu/evZWWlubYZ7PZlJaWpj/84Q9uzAwwnt1u16xZs/Tee+/po48+UlBQkLtTAkwxePBgZWZmKiMjw/HTp08fTZw4URkZGRTcqFUGDBhQ7vGPR44cUWBgoJsyAszz008/ycOjbEnq6ekpm83mpozMwZVu1DoxMTGaMmWK+vTpo1tuuUVLlixRQUGBpk6d6u7UAEPNnDlTb731ljZt2iSr1apz585Jkvz8/OTr6+vm7ADjWK3WcmsV3HDDDfL392cNA9Q6Dz30kPr376+nn35aEyZM0N69e7Vq1SqtWrXK3akBhhs1apQWLlyom266Sd26ddP+/fu1ePFi3Xvvve5OzVA8Mgy1UlJSkv7+97/r3LlzCg0N1dKlS9WvXz93pwUYymKxVLg/OTlZUVFR1zcZ4DoLCwvjkWGotbZu3aq5c+cqJydHQUFBiomJ0fTp092dFmC4ixcv6oknntB7772n3NxctWrVSpGRkZo3b568vb3dnZ5hKLoBAAAAADAJ93QDAAAAAGASim4AAAAAAExC0Q0AAAAAgEkougEAAAAAMAlFNwAAAAAAJqHoBgAAAADAJBTdAAAAAACYhKIbAAAAAACTUHQDAFAHbdy4UR06dJCnp6eio6PdnY5LoqKiNHr0aHenAQBAhSi6AQCopqioKFksFj3zzDNl9m/cuFEWi8WxvWPHDlksFv34448VtvPkk08qNDS00n7CwsJksVhksVhUv3593XzzzUpISJDdbnf5NcyYMUPjxo3TyZMnNX/+/Erj9u/fr4iICLVs2VI+Pj4KDAxUeHi4tmzZYkgeRnjhhRf06quvujsNAAAqRNENAMA1qF+/vhITE/XDDz+Y2s/06dN19uxZZWdna+7cuZo3b55eeukll9rMz89Xbm6uhg8frlatWslqtVYYt2nTJv3+979Xfn6+XnvtNWVlZSk1NVVjxozR448/rry8PJfyMIqfn58aN27s7jQAAKgQRTcAANdgyJAhCggIUEJCgqn9NGjQQAEBAQoMDNTUqVPVo0cPbd++3enf/PDDD5o8ebKaNGmiBg0aaMSIEcrJyZFUcvW9tMi+7bbbZLFYtGPHjnJtFBQUaNq0aRo5cqTef/99DRs2TO3atVOXLl00bdo0HThwQH5+fpKk4uJiTZs2TUFBQfL19VWnTp30wgsvlGkvLCys3DT20aNHKyoqyrG9fPlydezYUfXr11eLFi00btw4x7H169crODhYvr6+8vf315AhQ1RQUCCp/PTy1NRU/d///Z8aN24sf39/hYeH67///a/j+PHjx2WxWLRhwwYNGjRIDRo0UEhIiHbv3u30fQUA4FpQdAMAcA08PT319NNPa9myZTp16pTp/dntdn366ac6fPiwvL29ncZGRUVp37592rx5s3bv3i273a477rhDRUVF6t+/v7KzsyVJ7777rs6ePav+/fuXa+PDDz/Ud999p4cffrjSfkqn0ttsNrVu3VrvvPOODh06pHnz5unRRx9VSkpKlV/fvn37NHv2bD311FPKzs5WamqqBg4cKEk6e/asIiMjde+99yorK0s7duzQ2LFjK53eXlBQoJiYGO3bt09paWny8PDQmDFjZLPZysQ99thjmjNnjjIyMnTzzTcrMjJSly9frnLOAABUhZe7EwAAoKYaM2aMQkNDFRcXp1deecWUPpYvX67Vq1ersLBQRUVFql+/vmbPnl1pfE5OjjZv3qxdu3Y5iuk1a9aoTZs22rhxo8aPH6/mzZtLkpo2baqAgIAK2zly5IgkqVOnTo596enpGjRokGN73bp1Cg8PV7169RQfH+/YHxQUpN27dyslJUUTJkyo0us8ceKEbrjhBoWHh8tqtSowMFA9e/aUVFJ0X758WWPHjlVgYKAkKTg4uNK27rrrrjLb//jHP9SsWTMdOnRI3bt3d+yfM2eORo4cKUmKj49Xt27ddPToUXXu3LlKOQMAUBVc6QYAwAWJiYmO+53NMHHiRGVkZGjXrl0aMWKEHnvssQqvTJfKysqSl5eX+vXr59jn7++vTp06uZxjjx49lJGRoYyMDBUUFJS5Kvziiy+qd+/eatasmRo2bKhVq1bpxIkTVW576NChCgwMVLt27XTPPfdozZo1+umnnyRJISEhGjx4sIKDgzV+/Hi9/PLLTu+lz8nJUWRkpNq1a6dGjRqpbdu2klQunx49ejh+b9mypSQpNze3yjkDAFAVFN0AALhg4MCBGj58uObOnWtK+35+furQoYP69u2rlJQUJSUl6V//+pcpfV2pY8eOkuSYii5JPj4+6tChgzp06FAmdt26dZozZ46mTZumDz/8UBkZGZo6daoKCwsdMR4eHuWmgxcVFTl+t1qt+vLLL7V27Vq1bNlS8+bNU0hIiH788Ud5enpq+/bt2rZtm7p27aply5apU6dOOnbsWIW5jxo1St9//71efvll7dmzR3v27JGkMvlIUr169Ry/XzlVHgAAI1F0AwDgomeeeUZbtmwxfSGuhg0b6sEHH9ScOXMqvZ+5S5cuunz5sqPQlKTvvvtO2dnZ6tq1a5X7GjZsmJo2barExMSrxpZOZb///vvVs2dPdejQoczCZZLUrFkznT171rFdXFysgwcPlonx8vLSkCFDtGjRIv3nP//R8ePH9dFHH0kqKYoHDBig+Ph47d+/X97e3nrvvffK5VL6Wh9//HENHjxYXbp0MX2FeQAAnOGebgAAXBQcHKyJEydq6dKlFR7PzMws81gui8WikJAQSdLPP/+sjIyMMvFWq1Xt27evsK0ZM2Zo/vz5evfdd8us7l2qY8eOuvPOOzV9+nStXLlSVqtVsbGx+t3vfqc777yzyq+pYcOGWr16tSIiIjRy5EjNnj1bHTt2VH5+vlJTUyWVLCZX2ufrr7+uf/7znwoKCtIbb7yh9PR0BQUFOdq77bbbFBMTo/fff1/t27fX4sWLyzy/fOvWrfrqq680cOBANWnSRB988IFsNps6deqkPXv2KC0tTcOGDVPz5s21Z88enT9/Xl26dCmXd5MmTeTv769Vq1apZcuWOnHihGJjY6v8ugEAMBpFNwAABnjqqaf09ttvV3isdBXuUp6eno77oY8cOeJYMKzU4MGDK51C3rRpU02ePFlPPvmkxo4dKw+P8pPWkpOT9eCDDyo8PFyFhYUaOHCgPvjggzLTqatizJgx+vzzz5WYmKjJkyfr+++/l5+fn/r06eNYRE0q+Y+A/fv3KyIiQhaLRZGRkbr//vu1bds2R1v33nuvDhw4oMmTJ8vLy0sPPfRQmUXZGjdurA0bNujJJ5/UL7/8oo4dO2rt2rXq1q2bsrKytHPnTi1ZskQXLlxQYGCgnnvuOY0YMaJczh4eHlq3bp1mz56t7t27q1OnTlq6dKnCwsKq9doBADCKxV7Z/DQAAAAAAOAS7ukGAAAAAMAkFN0AAAAAAJiEohsAAAAAAJNQdAMAAAAAYBKKbgAAAAAATELRDQAAAACASSi6AQAAAAAwCUU3AAAAAAAmoegGAAAAAMAkFN0AAAAAAJiEohsAAAAAAJNQdAMAAAAAYJL/B6FMx1y06+wzAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "A note on the Likelihood Ratio\n",
    "\n",
    "It seems that the float computation error compounds strongly when computing the ratio, \n",
    "this is simply a result of small values and the way relative error scales\n",
    "\n",
    "Below is the example for the Guassian Component only\n",
    "\n",
    "Since the MLE tables are close, and the log Likelihoods are close no further evaluation is required \n",
    "and this is simply an inherent numerical problem\n",
    "\n",
    "\"\"\"\n",
    "likelihoodFunctionGauss = LikelihoodFunctionJAX.gaussian_approx(\n",
    "                                            p_dpe = p_dpe,\n",
    "                                            )\n",
    "\n",
    "likelihoodMLEFunctionGauss = LikelihoodFunctionJAX.gaussian_approx_MLE(\n",
    "                                    p_dpe = p_dpe,\n",
    "                                    )\n",
    "\n",
    "lossfunc_Gauss = LikelihoodFunctionJAX.lossFuncGenerator(\n",
    "    likelihoodFunction=likelihoodFunctionGauss,\n",
    "    ratio=True,\n",
    "    likelihoodMLEFunction=likelihoodMLEFunctionGauss,\n",
    "    log = True,\n",
    ")\n",
    "\n",
    "ltfgauss = tf_implement.gaussian_likelihood\n",
    "ltfmlegauss = lambda x,  std: ltfgauss(x, x, std) #As implemented in tf llr func\n",
    "lossfunctfGauss = tf_implement.gaussian_log_likelihood_ratio\n",
    "\n",
    "x= np.random.uniform(3,1000, size=n_samples * n_pmts).astype('float32')\n",
    "mu = x + np.random.uniform(-3,3, size=n_samples * n_pmts).astype('float32')\n",
    "stds = np.random.uniform(0.05, 0.95, size=n_samples * n_pmts).astype('float32')\n",
    "\n",
    "# Compare each corresponding component\n",
    "tf_gauss = ltfgauss(x, mu, stds)\n",
    "jax_gauss = likelihoodFunctionGauss(x, mu, stds)\n",
    "print(\"Guassian Likelihood\")\n",
    "print(np.allclose(tf_gauss, jax_gauss))\n",
    "\n",
    "tf_gauss_mle = ltfmlegauss(x, stds)\n",
    "jax_gauss_mle = likelihoodMLEFunctionGauss(x, stds)\n",
    "print(\"Guassian MLE Likelihood\")\n",
    "print(np.allclose(tf_gauss_mle, jax_gauss_mle))\n",
    "\n",
    "# Compare the loss functions\n",
    "tf_loss_gauss = lossfunctfGauss(x, mu, stds)\n",
    "jax_loss_gauss = lossfunc_Gauss(x, mu, stds)\n",
    "print(\"Loss function Gaussian\")\n",
    "print(np.allclose(tf_loss_gauss, jax_loss_gauss))\n",
    "print(np.isclose(tf_loss_gauss, jax_loss_gauss).mean())\n",
    "print('max relative diff:', (np.abs(tf_loss_gauss - jax_loss_gauss)/np.maximum(np.abs(tf_loss_gauss), 1e-10)).max())\n",
    "\n",
    "print(\"Sanity Check\")\n",
    "def do_NLLR(log_like, mle):\n",
    "    def NLLR(x, mu,std):\n",
    "        return -2*(log_like(x,mu,std) - mle(x,std))\n",
    "    return NLLR\n",
    "tf_nllr_gauss = do_NLLR(ltfgauss, ltfmlegauss)(x, mu,stds)\n",
    "jax_nllr_gauss = do_NLLR(likelihoodFunctionGauss, likelihoodMLEFunctionGauss)(x, mu,stds)\n",
    "print(\"NLLR Gaussian\")\n",
    "print(np.allclose(tf_nllr_gauss, jax_nllr_gauss))\n",
    "print(np.isclose(tf_nllr_gauss, jax_nllr_gauss).mean())\n",
    "print('max relative diff:', (np.abs(tf_nllr_gauss - jax_nllr_gauss)/np.maximum(np.abs(tf_nllr_gauss), 1e-10)).max())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Histogram parameters\n",
    "bins = 200\n",
    "\n",
    "# Compute histograms\n",
    "hist_tf, bin_edges = np.histogram(tf_loss_gauss, bins=bins)\n",
    "hist_jax, _ = np.histogram(jax_loss_gauss, bins=bin_edges)\n",
    "\n",
    "bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "bin_differences = hist_tf - hist_jax\n",
    "\n",
    "\n",
    "# Plot\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8), gridspec_kw={'height_ratios': [3, 1]})\n",
    "\n",
    "\n",
    "# First subplot: original histograms\n",
    "ax1.hist(tf_loss_gauss, bins=bins, alpha=0.5, label='TF Loss Gaussian', color='blue')\n",
    "ax1.hist(jax_loss_gauss, bins=bins, alpha=0.5, label='JAX Loss Gaussian', color='red', histtype='step')\n",
    "ax1.set_yscale('log')\n",
    "ax1.set_xlabel('NLLR of Gaussian')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.legend()\n",
    "\n",
    "# Second subplot: differences\n",
    "ax2.bar(bin_centers, bin_differences, width=np.diff(bin_edges), color='green', alpha=0.7)\n",
    "ax2.axhline(0, color='black', linestyle='--')\n",
    "ax2.set_xlabel('NLLR of Gaussian')\n",
    "ax2.set_ylabel('TF - JAX Bin Difference')\n",
    "ax2.set_title('Bin Differences between TF and JAX Loss Gaussian')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow vs Numpy/Numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNotes on closeness of values\\n\\nGaussian component is equivalent using np.isclose \\nBinomial is close using rtol = 1.16e-5 and atol = 0 (around 2% of data tested)\\nPoisson is close using rtol = 5e-5 and atol = 0 \\n\\nExact Likelihood aligns with rtol = 3e-5 and atol = 0 \\n\\nLUT with rtol 3e-5 and atol = 0\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare LUTS for Numpy\n",
    "\n",
    "from TensorflowImplementation.LikelihoodFunction import LikelihoodRatio\n",
    "from Numpy_NumbaReimplementation import np_LikelihoodFunction as LikelihoodFunction\n",
    "\n",
    "\n",
    "tf_implement = LikelihoodRatio( n_pmts, \n",
    "                                return_ratio = return_ratio, \n",
    "                                switching_signal = switching_signal, \n",
    "                                n_sigma = n_sigma,\n",
    "                                sigma_min = sigma_min, \n",
    "                                sigma_max = sigma_max, \n",
    "                                z = z,\n",
    "                                p_dpe = p_dpe, \n",
    "                                nan_safe = nan_safe, \n",
    "                                nan_safe_value = nan_safe_value, \n",
    "                                m = m,  \n",
    "                                mle_estimator = mle_estimator, \n",
    "                              )\n",
    "# Precompute LUT table\n",
    "tf_implement.std.assign(stds)\n",
    "tf_implement.set_call_mode(\"LUT_untrainable_std\", return_ratio = True)\n",
    "\n",
    "tf_LUT = tf_implement.L_table\n",
    "tf_LUT_mle = tf_implement.L_mle_table\n",
    "tf_x_domain = tf_implement.x_domain\n",
    "tf_mu_domain = tf_implement.mu_domain\n",
    "\n",
    "jax_LUT, jax_LUT_MLE, jax_x_domain, jax_mu_domain = LikelihoodFunction.generate_LUT(\n",
    "    m = m,\n",
    "    p = p_dpe,\n",
    "    switching_signal = switching_signal,\n",
    "    gaussian_stds = stds,\n",
    "    n_sigma = n_sigma, \n",
    "    obs_min = obs_min,\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "Notes on closeness of values\n",
    "\n",
    "Gaussian component is equivalent using np.isclose \n",
    "Binomial is close using rtol = 1.16e-5 and atol = 0 (around 2% of data tested)\n",
    "Poisson is close using rtol = 5e-5 and atol = 0 \n",
    "\n",
    "Exact Likelihood aligns with rtol = 3e-5 and atol = 0 \n",
    "\n",
    "LUT with rtol 3e-5 and atol = 0\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the two methods produce the same numerical results\n",
    "assert np.allclose(tf_x_domain, jax_x_domain), \"x domains do not match!\"\n",
    "assert np.allclose(tf_mu_domain, jax_mu_domain), \"mu domains do not match!\"\n",
    "# Needed a tiny atol because of null entries not being exactly null \n",
    "assert np.allclose(jax_LUT, tf_LUT, rtol = 3e-5, atol=1e-30), \"LUTs do not match!\"\n",
    "assert np.allclose(tf_LUT_mle, jax_LUT_MLE, rtol = 2e-5, atol=0), \"MLE LUTs do not match!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNotes on closeness of values\\n\\nGaussian component is equivalent using np.isclose \\nBinomial is close using rtol = 1.16e-5 and atol = 0 (around 2% of data tested)\\nPoisson is close using rtol = 5e-5 and atol = 0 \\n\\nExact Likelihood aligns with rtol = 3e-5 and atol = 0 \\n\\nLUT with rtol 3e-5 and atol = 0\\n\\n'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare LUTS for Numba\n",
    "\n",
    "from TensorflowImplementation.LikelihoodFunction import LikelihoodRatio\n",
    "from Numpy_NumbaReimplementation import nb_LikelihoodFunction as LikelihoodFunction\n",
    "\n",
    "\n",
    "jax_LUT, jax_LUT_MLE, jax_x_domain, jax_mu_domain = LikelihoodFunction.generate_LUT(\n",
    "    m = m,\n",
    "    p = p_dpe,\n",
    "    switching_signal = switching_signal,\n",
    "    gaussian_stds = stds,\n",
    "    n_sigma = n_sigma, \n",
    "    obs_min = obs_min,\n",
    "    float_type=np.float32,  # Ensure float32 for consistency with TensorFlow\n",
    ")\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.keras.mixed_precision.set_global_policy(\"float32\")\n",
    "tf_implement = LikelihoodRatio( n_pmts, \n",
    "                                return_ratio = return_ratio, \n",
    "                                switching_signal = switching_signal, \n",
    "                                n_sigma = n_sigma,\n",
    "                                sigma_min = sigma_min, \n",
    "                                sigma_max = sigma_max, \n",
    "                                z = z,\n",
    "                                p_dpe = p_dpe, \n",
    "                                nan_safe = nan_safe, \n",
    "                                nan_safe_value = nan_safe_value, \n",
    "                                m = m,  \n",
    "                                mle_estimator = mle_estimator, \n",
    "                              )\n",
    "# Precompute LUT table\n",
    "tf_implement.std.assign(stds)\n",
    "tf_implement.set_call_mode(\"LUT_untrainable_std\", return_ratio = True)\n",
    "\n",
    "tf_LUT = tf_implement.L_table\n",
    "tf_LUT_mle = tf_implement.L_mle_table\n",
    "tf_x_domain = tf_implement.x_domain\n",
    "tf_mu_domain = tf_implement.mu_domain\n",
    "\n",
    "\"\"\"\n",
    "Notes on closeness of values\n",
    "\n",
    "Gaussian component is equivalent using np.isclose \n",
    "Binomial is close using rtol = 1.16e-5 and atol = 0 (around 2% of data tested)\n",
    "Poisson is close using rtol = 5e-5 and atol = 0 \n",
    "\n",
    "Exact Likelihood aligns with rtol = 3e-5 and atol = 0 \n",
    "\n",
    "LUT with rtol 3e-5 and atol = 0\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the two methods produce the same numerical results\n",
    "assert np.allclose(tf_x_domain, jax_x_domain), \"x domains do not match!\"\n",
    "assert np.allclose(tf_mu_domain, jax_mu_domain), \"mu domains do not match!\"\n",
    "# Needed a tiny atol because of null entries not being exactly null \n",
    "assert np.allclose(jax_LUT, tf_LUT, rtol = 3e-5, atol=1e-30), \"LUTs do not match!\"\n",
    "assert np.allclose(tf_LUT_mle, jax_LUT_MLE, rtol = 2e-5, atol=0), \"MLE LUTs do not match!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <bound method LikelihoodRatio.exact_neg_log_likelihood of <TensorflowImplementation.LikelihoodFunction.LikelihoodRatio object at 0x7207c4745a30>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Exact only branch\n",
      "True\n",
      "Gaussian only branch\n",
      "True\n",
      "Mixed branch\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# parent exact  nb\n",
    "from TensorflowImplementation.LikelihoodFunction import LikelihoodRatio\n",
    "from Numpy_NumbaReimplementation import LikelihoodFunction as LikelihoodFunction\n",
    "# Now full chain with parent call exact\n",
    "tf_implement = LikelihoodRatio( n_pmts, \n",
    "                                return_ratio = return_ratio, \n",
    "                                switching_signal = switching_signal, \n",
    "                                n_sigma = n_sigma,\n",
    "                                sigma_min = sigma_min, \n",
    "                                sigma_max = sigma_max, \n",
    "                                z = z,\n",
    "                                p_dpe = p_dpe, \n",
    "                                nan_safe = nan_safe, \n",
    "                                nan_safe_value = nan_safe_value, \n",
    "                                m = m,  \n",
    "                                mle_estimator = mle_estimator, \n",
    "                              )\n",
    "tf_implement.std.assign(stds)\n",
    "tf_implement.set_call_mode(\"exact\", return_ratio = False)\n",
    "tf_implement.std.assign(stds)\n",
    "\n",
    "\n",
    "jax_implement = LikelihoodFunction.parent_gen(stds,\n",
    "                                                 method = 'Exact',\n",
    "                                                 return_ratio=False,\n",
    "                                                 switching_signal = switching_signal,\n",
    "                                                 p_dpe = p_dpe,\n",
    "                                                 n_sigma = n_sigma,\n",
    "                                                 m = m,\n",
    "                                                 usenumba=True,\n",
    "                                                 )\n",
    "\n",
    "# Generate some random data to test\n",
    "n_samples = 1000\n",
    "x= np.random.uniform(-3,40, size=n_samples * n_pmts).reshape(n_samples, n_pmts).astype('float32')\n",
    "mu = np.clip(x, 0, None) / np.sum(np.where(x >= 0, x, 0), axis=1, keepdims=True)  # Normalize mu to sum to 1\n",
    "\n",
    "res1 = tf_implement(mu, x)\n",
    "res2 = jax_implement(x = x, mu = mu)\n",
    "print(\"Exact only branch\")\n",
    "print(np.allclose(res1, res2))\n",
    "\n",
    "n_samples = 1000\n",
    "x= np.random.uniform(40,1000, size=n_samples * n_pmts).reshape(n_samples, n_pmts).astype('float32')\n",
    "mu = x / np.sum(np.where(x >= 0, x, 0), axis=1, keepdims=True)  # Normalize mu to sum to 1\n",
    "\n",
    "res1 = tf_implement(mu, x)\n",
    "res2 = jax_implement(x = x, mu = mu)\n",
    "\n",
    "print(\"Gaussian only branch\")\n",
    "print(np.allclose(res1, res2))\n",
    "\n",
    "n_samples = 1000\n",
    "x= np.random.uniform(-3,100, size=n_samples * n_pmts).reshape(n_samples, n_pmts).astype('float32')\n",
    "mu = x / np.sum(np.where(x >= 0, x, 0), axis=1, keepdims=True)  # Normalize mu to sum to 1\n",
    "\n",
    "res1 = tf_implement(mu, x)\n",
    "res2 = jax_implement(x = x, mu = mu)\n",
    "\n",
    "print(\"Mixed branch\")\n",
    "print(np.allclose(res1, res2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact only branch\n",
      "False\n",
      "0.9861\n",
      "Gaussian only branch\n",
      "False\n",
      "0.35216\n",
      "Mixed branch\n",
      "False\n",
      "0.60479\n"
     ]
    }
   ],
   "source": [
    "# parent : LUT ratio nb\n",
    "from TensorflowImplementation.LikelihoodFunction import LikelihoodRatio\n",
    "from Numpy_NumbaReimplementation import LikelihoodFunction as LikelihoodFunction\n",
    "\n",
    "tf_implement = LikelihoodRatio( n_pmts, \n",
    "                                return_ratio = True, \n",
    "                                switching_signal = switching_signal, \n",
    "                                n_sigma = n_sigma,\n",
    "                                sigma_min = sigma_min, \n",
    "                                sigma_max = sigma_max, \n",
    "                                z = z,\n",
    "                                p_dpe = p_dpe, \n",
    "                                nan_safe = False, \n",
    "                                nan_safe_value = nan_safe_value, \n",
    "                                m = m,  \n",
    "                                mle_estimator = mle_estimator, \n",
    "                              )\n",
    "tf_implement.std.assign(stds)\n",
    "tf_implement.set_call_mode(\"LUT_untrainable_std\", return_ratio = True)\n",
    "\n",
    "jax_implement = LikelihoodFunction.parent_gen(stds,\n",
    "                                                 method = 'LUT',\n",
    "                                                 return_ratio=True,\n",
    "                                                 switching_signal = switching_signal,\n",
    "                                                 p_dpe = p_dpe,\n",
    "                                                 n_sigma = n_sigma,\n",
    "                                                 m = m,\n",
    "                                                 usenumba=True,\n",
    "                                                 )\n",
    "\n",
    "# Generate some random data to test\n",
    "n_samples = 1000\n",
    "x= np.random.uniform(-3,40, size=n_samples * n_pmts).reshape(n_samples, n_pmts).astype('float32')\n",
    "mu = np.clip(x, 0, None) / np.sum(np.where(x >= 0, x, 0), axis=1, keepdims=True)  # Normalize mu to sum to 1\n",
    "\n",
    "res1 = tf_implement(mu, x)\n",
    "res2 = jax_implement(x = x, mu = mu)\n",
    "print(\"Exact only branch\")\n",
    "print(np.allclose(res1, res2, rtol = 3e-5, atol=1e-10))\n",
    "print(np.isclose(res1, res2, rtol = 3e-5, atol=1e-10).mean())\n",
    "\n",
    "n_samples = 1000\n",
    "x= np.random.uniform(40,1000, size=n_samples * n_pmts).reshape(n_samples, n_pmts).astype('float32')\n",
    "mu = x / np.sum(np.where(x >= 0, x, 0), axis=1, keepdims=True)  # Normalize mu to sum to 1\n",
    "\n",
    "res1 = tf_implement(mu, x)\n",
    "res2 = jax_implement(x = x, mu = mu)\n",
    "\n",
    "print(\"Gaussian only branch\")\n",
    "print(np.allclose(res1, res2, rtol = 3e-5, atol=1e-10))\n",
    "print(np.isclose(res1, res2, rtol = 3e-5, atol=1e-10).mean())\n",
    "\n",
    "n_samples = 1000\n",
    "x= np.random.uniform(-3,100, size=n_samples * n_pmts).reshape(n_samples, n_pmts).astype('float32')\n",
    "mu = np.clip(x, 0, None) / np.sum(np.where(x >= 0, x, 0), axis=1, keepdims=True)  # Normalize mu to sum to 1\n",
    "\n",
    "res1 = tf_implement(mu, x)\n",
    "res2 = jax_implement(x = x, mu = mu)\n",
    "\n",
    "print(\"Mixed branch\")\n",
    "print(np.allclose(res1, res2, rtol = 3e-5, atol=0))\n",
    "print(np.isclose(res1, res2, rtol = 3e-5, atol=0).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact only branch\n",
      "True\n",
      "Gaussian only branch\n",
      "True\n",
      "Mixed branch\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# parent exact np\n",
    "tf_implement = LikelihoodRatio( n_pmts, \n",
    "                                return_ratio = return_ratio, \n",
    "                                switching_signal = switching_signal, \n",
    "                                n_sigma = n_sigma,\n",
    "                                sigma_min = sigma_min, \n",
    "                                sigma_max = sigma_max, \n",
    "                                z = z,\n",
    "                                p_dpe = p_dpe, \n",
    "                                nan_safe = nan_safe, \n",
    "                                nan_safe_value = nan_safe_value, \n",
    "                                m = m,  \n",
    "                                mle_estimator = mle_estimator, \n",
    "                              )\n",
    "tf_implement.std.assign(stds)\n",
    "tf_implement.set_call_mode(\"exact\", return_ratio = False)\n",
    "tf_implement.std.assign(stds)\n",
    "\n",
    "jax_implement = LikelihoodFunction.parent_gen(stds,\n",
    "                                                 method = 'Exact',\n",
    "                                                 return_ratio=False,\n",
    "                                                 switching_signal = switching_signal,\n",
    "                                                 p_dpe = p_dpe,\n",
    "                                                 n_sigma = n_sigma,\n",
    "                                                 m = m,\n",
    "                                                 usenumba=False,\n",
    "                                                 )\n",
    "\n",
    "# Generate some random data to test\n",
    "n_samples = 1000\n",
    "x= np.random.uniform(-3,40, size=n_samples * n_pmts).reshape(n_samples, n_pmts).astype('float32')\n",
    "mu = np.clip(x, 0, None) / np.sum(np.where(x >= 0, x, 0), axis=1, keepdims=True)  # Normalize mu to sum to 1\n",
    "\n",
    "res1 = tf_implement(mu, x)\n",
    "res2 = jax_implement(x = x, mu = mu)\n",
    "print(\"Exact only branch\")\n",
    "print(np.allclose(res1, res2))\n",
    "\n",
    "n_samples = 1000\n",
    "x= np.random.uniform(40,1000, size=n_samples * n_pmts).reshape(n_samples, n_pmts).astype('float32')\n",
    "mu = x / np.sum(np.where(x >= 0, x, 0), axis=1, keepdims=True)  # Normalize mu to sum to 1\n",
    "\n",
    "res1 = tf_implement(mu, x)\n",
    "res2 = jax_implement(x = x, mu = mu)\n",
    "\n",
    "print(\"Gaussian only branch\")\n",
    "print(np.allclose(res1, res2))\n",
    "\n",
    "n_samples = 1000\n",
    "x= np.random.uniform(-3,100, size=n_samples * n_pmts).reshape(n_samples, n_pmts).astype('float32')\n",
    "mu = x / np.sum(np.where(x >= 0, x, 0), axis=1, keepdims=True)  # Normalize mu to sum to 1\n",
    "\n",
    "res1 = tf_implement(mu, x)\n",
    "res2 = jax_implement(x = x, mu = mu)\n",
    "\n",
    "print(\"Mixed branch\")\n",
    "print(np.allclose(res1, res2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact only branch\n",
      "False\n",
      "0.98126\n",
      "Gaussian only branch\n",
      "False\n",
      "0.51932\n",
      "Mixed branch\n",
      "False\n",
      "0.69698\n"
     ]
    }
   ],
   "source": [
    "# parent LUT ratio np \n",
    "tf_implement = LikelihoodRatio( n_pmts, \n",
    "                                return_ratio = True, \n",
    "                                switching_signal = switching_signal, \n",
    "                                n_sigma = n_sigma,\n",
    "                                sigma_min = sigma_min, \n",
    "                                sigma_max = sigma_max, \n",
    "                                z = z,\n",
    "                                p_dpe = p_dpe, \n",
    "                                nan_safe = False, \n",
    "                                nan_safe_value = nan_safe_value, \n",
    "                                m = m,  \n",
    "                                mle_estimator = mle_estimator, \n",
    "                              )\n",
    "tf_implement.std.assign(stds)\n",
    "tf_implement.set_call_mode(\"LUT_untrainable_std\", return_ratio = True)\n",
    "\n",
    "jax_implement = LikelihoodFunction.parent_gen(stds,\n",
    "                                                 method = 'LUT',\n",
    "                                                 return_ratio=True,\n",
    "                                                 switching_signal = switching_signal,\n",
    "                                                 p_dpe = p_dpe,\n",
    "                                                 n_sigma = n_sigma,\n",
    "                                                 m = m,\n",
    "                                                 usenumba=False,\n",
    "                                                 )\n",
    "\n",
    "# Generate some random data to test\n",
    "n_samples = 1000\n",
    "x= np.random.uniform(-3,40, size=n_samples * n_pmts).reshape(n_samples, n_pmts).astype('float32')\n",
    "mu = np.clip(x, 0, None) / np.sum(np.where(x >= 0, x, 0), axis=1, keepdims=True)  # Normalize mu to sum to 1\n",
    "\n",
    "res1 = tf_implement(mu, x)\n",
    "res2 = jax_implement(x = x, mu = mu)\n",
    "print(\"Exact only branch\")\n",
    "print(np.allclose(res1, res2, rtol = 3e-5, atol=0))\n",
    "print(np.isclose(res1, res2, rtol = 3e-5, atol=0).mean())\n",
    "\n",
    "n_samples = 1000\n",
    "x= np.random.uniform(40,1000, size=n_samples * n_pmts).reshape(n_samples, n_pmts).astype('float32')\n",
    "mu = x / np.sum(np.where(x >= 0, x, 0), axis=1, keepdims=True)  # Normalize mu to sum to 1\n",
    "\n",
    "res1 = tf_implement(mu, x)\n",
    "res2 = jax_implement(x = x, mu = mu)\n",
    "\n",
    "print(\"Gaussian only branch\")\n",
    "print(np.allclose(res1, res2, rtol = 3e-5, atol=0))\n",
    "print(np.isclose(res1, res2, rtol = 3e-5, atol=0).mean())\n",
    "\n",
    "n_samples = 1000\n",
    "x= np.random.uniform(-3,100, size=n_samples * n_pmts).reshape(n_samples, n_pmts).astype('float32')\n",
    "mu = np.clip(x, 0, None) / np.sum(np.where(x >= 0, x, 0), axis=1, keepdims=True)  # Normalize mu to sum to 1\n",
    "\n",
    "res1 = tf_implement(mu, x)\n",
    "res2 = jax_implement(x = x, mu = mu)\n",
    "\n",
    "print(\"Mixed branch\")\n",
    "print(np.allclose(res1, res2, rtol = 3e-5, atol=0))\n",
    "print(np.isclose(res1, res2, rtol = 3e-5, atol=0).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Methods \n",
    "\n",
    "Only need to implement the final shared model whatever it is going to be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cython Likelihood Function\n",
    "\n",
    "Fully implemented but not further used, noticed it was going to be much more of a pain to do so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content of stderr:\n",
      "In file included from /opt/XENONnT/anaconda/envs/XENONnT_el9.2024.10.4/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h:1929,\n",
      "                 from /opt/XENONnT/anaconda/envs/XENONnT_el9.2024.10.4/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h:12,\n",
      "                 from /opt/XENONnT/anaconda/envs/XENONnT_el9.2024.10.4/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h:5,\n",
      "                 from /root/.cache/ipython/cython/_cython_magic_3079db3498f839f2772c74c2b597ba83c2d51e43.c:1260:\n",
      "/opt/XENONnT/anaconda/envs/XENONnT_el9.2024.10.4/lib/python3.9/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2: warning: #warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [-Wcpp]\n",
      "   17 | #warning \"Using deprecated NumPy API, disable it with \" \\\n",
      "      |  ^~~~~~~"
     ]
    }
   ],
   "source": [
    "%%cython\n",
    "# cython: boundscheck=False, wraparound=False\n",
    "# distutils: extra_compile_args = -fopenmp\n",
    "# distutils: extra_link_args    = -fopenmp\n",
    "\n",
    "from libc.stdlib   cimport malloc, free\n",
    "from libc.math     cimport sqrt, log, M_PI, lgamma, lgammaf, exp, floor, floorf, INFINITY, fabs, fabsf\n",
    "from cython.parallel import prange\n",
    "cimport cython\n",
    "\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "\n",
    "ctypedef fused DType:\n",
    "    float\n",
    "    double\n",
    "\n",
    "ctypedef fused NPDType:\n",
    "    np.float32_t\n",
    "    np.float64_t\n",
    "\n",
    "###           Make ph_pe_dpmain\n",
    "cdef inline DType[::1] _make_domain(DType maximum):\n",
    "    cdef int length = <int>(maximum) + 1\n",
    "    cdef DType *buf = <DType *> malloc(length * sizeof(DType))\n",
    "    if not buf:\n",
    "        raise MemoryError()\n",
    "    cdef int i\n",
    "    with nogil:\n",
    "        for i in range(length):\n",
    "            buf[i] = i\n",
    "    # cast to a length-checked 1D memoryview;\n",
    "    # Cython will free buf when this view is GC’d\n",
    "    return <DType[:length]>buf\n",
    "\n",
    "# 3) C-only helper, returns two memoryviews\n",
    "cdef tuple gen_pe_ph_domain(DType switching_signal,\n",
    "                             int   n_sigma,\n",
    "                             DType p_dpe):\n",
    "    cdef DType pe_max = switching_signal \\\n",
    "                       + n_sigma * sqrt(switching_signal) + 2\n",
    "    cdef DType ph_max = switching_signal/(1 + p_dpe) \\\n",
    "                       + n_sigma * sqrt(switching_signal/(1 + p_dpe)) + 2\n",
    "\n",
    "    cdef DType[::1] pe = _make_domain(pe_max)\n",
    "    cdef DType[::1] ph = _make_domain(ph_max)\n",
    "    return pe, ph\n",
    "\n",
    "# Likelihood functions\n",
    "\n",
    "cdef double _LOG2PI = 0.9189385332046727#0.5 * log(2.0 * M_PI)\n",
    "\n",
    "cdef inline DType gaussian_log_likelihood(DType x, DType mu, DType std) noexcept nogil:\n",
    "    return -( 0.5*((x - mu)/std)**2  + <DType>_LOG2PI + log(std) )\n",
    "\n",
    "# Use either float or double depending on input\n",
    "cdef inline DType mylgamma(DType x) noexcept nogil:\n",
    "    # sizeof(DType)==sizeof(float) is a compile‐time constant\n",
    "    if sizeof(DType) == sizeof(float):\n",
    "        # call the float version\n",
    "        return <DType>lgammaf(<float>x)\n",
    "    else:\n",
    "        # call the double version\n",
    "        return <DType>lgamma(<double>x)\n",
    "\n",
    "cdef inline DType myabs(DType x) noexcept nogil:\n",
    "    # sizeof(DType)==sizeof(float) is a compile‐time constant\n",
    "    if sizeof(DType) == sizeof(float):\n",
    "        # call the float version\n",
    "        return <DType>fabsf(<float>x)\n",
    "    else:\n",
    "        # call the double version\n",
    "        return <DType>fabs(<double>x)\n",
    "\n",
    "cdef inline DType myfloor(DType x) noexcept nogil:\n",
    "    # sizeof(DType)==sizeof(float) is a compile‐time constant\n",
    "    if sizeof(DType) == sizeof(float):\n",
    "        # call the float version\n",
    "        return <DType>floorf(<float>x)\n",
    "    else:\n",
    "        # call the double version\n",
    "        return <DType>floor(<double>x)\n",
    "\n",
    "cdef inline DType betaln(DType a, DType b) noexcept nogil:\n",
    "    if (a < 0.0) and (myfloor(a) == a): return <DType>INFINITY\n",
    "    if (b < 0.0) and (myfloor(b) == b): return <DType>INFINITY\n",
    "    return mylgamma(a) + mylgamma(b) - mylgamma(a + b)\n",
    "\n",
    "cdef inline DType binomial_pmf(DType n, DType p, DType k) noexcept nogil:\n",
    "    if (k < 0) or (k > n):\n",
    "        return <DType>0.0\n",
    "\n",
    "    cdef DType log_unnorm = k*log(p) + (n-k) * log(1-p)\n",
    "    cdef DType log_norm = betaln(1+k, 1+n-k) + log(n+1)\n",
    "    return exp(log_unnorm - log_norm)\n",
    "\n",
    "cdef inline DType poisson_pmf(DType n, DType n1plgamma, DType mu, DType logmu) noexcept nogil:\n",
    "    return ( <DType>0.0\n",
    "        if mu < 0.0\n",
    "        else exp(n * logmu - mu - n1plgamma)\n",
    "    )\n",
    "\n",
    "cdef DType* c_getBinomGrid(DType* pe, DType* ph, DType p, Py_ssize_t J, Py_ssize_t K, bint parallel) noexcept nogil:\n",
    "    cdef Py_ssize_t j, k, idx\n",
    "    cdef DType *buf = <DType*>malloc(J * K * sizeof(DType))\n",
    "    if not buf:\n",
    "        return NULL\n",
    "    if parallel:\n",
    "        for j in range(J):\n",
    "            for k in range(K):\n",
    "                idx = j * K + k\n",
    "                buf[idx] = binomial_pmf(\n",
    "                    ph[j], p, pe[k] - ph[j]\n",
    "                )\n",
    "    else:\n",
    "        for j in prange(J):\n",
    "            for k in range(K):\n",
    "                idx = j * K + k\n",
    "                buf[idx] = binomial_pmf(\n",
    "                    ph[j], p, pe[k] - ph[j]\n",
    "                )\n",
    "    return buf\n",
    "\n",
    "cdef DType[:, ::1] getBinomGrid(DType[::1] pe, DType[::1] ph, DType p, bint parallel) noexcept:\n",
    "    cdef Py_ssize_t K = pe.shape[0]\n",
    "    cdef Py_ssize_t J = ph.shape[0]\n",
    "    cdef DType *buf = c_getBinomGrid(&pe[0], &ph[0], p, J, K, parallel)\n",
    "    return <DType[:J, :K]>buf\n",
    "\n",
    "cdef DType c_exact_likelihood(DType x, \n",
    "                            DType mu, \n",
    "                            DType std, \n",
    "                            DType[::1] pe,\n",
    "                            DType[::1] sqrt_pe,\n",
    "                            DType[::1] ph,\n",
    "                            DType[:, ::1] b_grid\n",
    "                            ) noexcept nogil:\n",
    "    cdef int K = pe.shape[0]\n",
    "    cdef int J = ph.shape[0]\n",
    "    cdef Py_ssize_t j, k, idx\n",
    "    cdef DType nph, nphlgamma, a, b, c, s, npe, scale\n",
    "    s = 0.0\n",
    "\n",
    "    cdef DType logmu = log(mu)\n",
    "\n",
    "    for j in range(J):\n",
    "        nph = ph[j]\n",
    "        nphlgamma = mylgamma(nph + 1)\n",
    "        for k in range(K):\n",
    "            npe = pe[k]\n",
    "            scale = std * sqrt_pe[k]\n",
    "            if scale < 1e-10: scale = 1e-10\n",
    "            a = exp(gaussian_log_likelihood(x, npe, scale))\n",
    "            b = b_grid[j, k]\n",
    "            c = poisson_pmf(nph, nphlgamma, mu, logmu)\n",
    "            s += a * b * c\n",
    "    return s\n",
    "\n",
    "cdef inline DType compute_common_std(DType mu, DType std, DType p_dpe) noexcept nogil:\n",
    "    cdef DType val = (\n",
    "        mu * (1 + p_dpe)**2 + \n",
    "        mu * p_dpe *(1 - p_dpe) + \n",
    "        (sqrt(myabs(mu * (1+p_dpe))) * std**2)\n",
    "    )\n",
    "    return sqrt(val) if val > 1e-6 else sqrt(1e-6)\n",
    "\n",
    "cdef DType gaussian_approx(DType x, DType mu, DType std, DType p_dpe) noexcept nogil:\n",
    "    cdef DType npe_mean = mu * (1+p_dpe)\n",
    "    cdef DType combined_std = compute_common_std(mu, std, p_dpe)\n",
    "    return (\n",
    "        -0.5 * ((x - npe_mean) / combined_std) **2 \n",
    "        - log(combined_std)\n",
    "        - _LOG2PI\n",
    "    )\n",
    "\n",
    "cpdef np.ndarray[NPDType, ndim=1] c_exact_likelihood_array(\n",
    "        np.ndarray[NPDType, ndim=1] x,\n",
    "        np.ndarray[NPDType, ndim=1] mu,\n",
    "        np.ndarray[NPDType, ndim=1] std,\n",
    "        DType[::1] pe,\n",
    "        DType[::1] sqrt_pe,\n",
    "        DType[::1] ph,\n",
    "        DType[:, ::1] b_grid,\n",
    "        DType switching_signal, \n",
    "        DType p_dpe, \n",
    "        bint parallel=False\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Compute exact likelihood for each element of x, mu, std\n",
    "    using precomputed domains (pe, sqrt_pe, ph, b_grid).\n",
    "    Works for float32 and float64.\n",
    "    \"\"\"\n",
    "    cdef Py_ssize_t n = x.shape[0]\n",
    "    # 4) grab typed memoryviews\n",
    "    cdef DType[::1] xmv       = x\n",
    "    cdef DType[::1] muv       = mu\n",
    "    cdef DType[::1] stdmv     = std\n",
    "    # 5) allocate output array of matching dtype\n",
    "    cdef np.ndarray[NPDType, ndim=1] out = np.empty(n, dtype=x.dtype)\n",
    "    cdef DType[::1] outmv     = out\n",
    "    cdef Py_ssize_t i\n",
    "    # 6) loop under the GIL but no per-element Python overhead\n",
    "    if parallel:\n",
    "        for i in prange(n, schedule='dynamic', nogil=True):\n",
    "            if muv[i] < switching_signal:\n",
    "                outmv[i] = c_exact_likelihood(\n",
    "                    xmv[i], muv[i], stdmv[i],\n",
    "                    pe, sqrt_pe, ph, b_grid\n",
    "                )\n",
    "            else:\n",
    "                outmv[i] = gaussian_approx(  xmv[i], muv[i], stdmv[i], p_dpe)\n",
    "    else:\n",
    "        with nogil:\n",
    "            for i in range(n):\n",
    "                if muv[i] < switching_signal:\n",
    "                    outmv[i] = c_exact_likelihood(\n",
    "                        xmv[i], muv[i], stdmv[i],\n",
    "                        pe, sqrt_pe, ph, b_grid\n",
    "                    )\n",
    "                else:\n",
    "                    outmv[i] = gaussian_approx(  xmv[i], muv[i], stdmv[i], p_dpe)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "cpdef np.ndarray[NPDType, ndim=2] c_exact_likelihood_grid(\n",
    "        np.ndarray[NPDType, ndim=2] x,    # shape (B, K)\n",
    "        np.ndarray[NPDType, ndim=2] mu,   # shape (B, K)\n",
    "        np.ndarray[NPDType, ndim=1] std,  # shape (K,)\n",
    "        DType[::1]            pe,\n",
    "        DType[::1]            sqrt_pe,\n",
    "        DType[::1]            ph,\n",
    "        DType[:, ::1]         b_grid,\n",
    "        DType switching_signal, \n",
    "        DType p_dpe, \n",
    "        bint                  parallel=False):\n",
    "    \"\"\"\n",
    "    Compute per-element likelihood grid. Returns an array of shape (B,K) where\n",
    "        out[i,j] = c_exact_likelihood(x[i,j], mu[i,j], std[j], pe, sqrt_pe, ph, b_grid)\n",
    "    \"\"\"\n",
    "    cdef Py_ssize_t B = x.shape[0]\n",
    "    cdef Py_ssize_t K = x.shape[1]\n",
    "    # allocate output\n",
    "    cdef np.ndarray[NPDType, ndim=2] out = np.empty((B, K), dtype=x.dtype)\n",
    "\n",
    "    # memoryviews\n",
    "    cdef DType[:, ::1] xmv    = x\n",
    "    cdef DType[:, ::1] muv2d  = mu\n",
    "    cdef DType[::1]    stdmv  = std\n",
    "    cdef DType[:, ::1] outmv  = out\n",
    "\n",
    "    cdef Py_ssize_t i, j\n",
    "    \n",
    "    # tight C loops under nogil\n",
    "    # choose loop based on `parallel` flag\n",
    "    if parallel:\n",
    "        for i in prange(B, schedule='dynamic', nogil=True):\n",
    "            for j in range(K):\n",
    "                if muv2d[i, j] < switching_signal:\n",
    "                    outmv[i, j] = c_exact_likelihood(\n",
    "                        xmv[i, j],\n",
    "                        muv2d[i, j],\n",
    "                        stdmv[j],\n",
    "                        pe, sqrt_pe, ph, b_grid\n",
    "                        )\n",
    "                else:\n",
    "                    outmv[i, j] = gaussian_approx(  xmv[i, j],\n",
    "                                                    muv2d[i, j],\n",
    "                                                    stdmv[j], p_dpe)\n",
    "    else:\n",
    "        with nogil:\n",
    "            for i in range(B):\n",
    "                for j in range(K):\n",
    "                    if muv2d[i, j] < switching_signal:\n",
    "                        outmv[i, j] = c_exact_likelihood(\n",
    "                            xmv[i, j],\n",
    "                            muv2d[i, j],\n",
    "                            stdmv[j],\n",
    "                            pe, sqrt_pe, ph, b_grid\n",
    "                        )\n",
    "                    else:\n",
    "                        outmv[i, j] = gaussian_approx(  xmv[i, j],\n",
    "                                                        muv2d[i, j],\n",
    "                                                        stdmv[j], p_dpe)\n",
    "    return out\n",
    "\n",
    "cpdef DType[::1] sqrt_array(DType[::1] arr) noexcept:\n",
    "    \"\"\"\n",
    "    Elementwise C-sqrt over a float32 memoryview.\n",
    "    \"\"\"\n",
    "    cdef Py_ssize_t n = arr.shape[0]\n",
    "    cdef DType* buf = <DType*>malloc(n * sizeof(DType))\n",
    "    cdef Py_ssize_t i\n",
    "    for i in range(n):\n",
    "        buf[i] = sqrt(arr[i])\n",
    "    return <DType[:n]>buf\n",
    "\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "def exact_likelihood_generator(p, switching_signal = 40., n_sigma = 5, float32 = True, linear_input = False, parallel = False):\n",
    "    if float32:\n",
    "        pe, ph = gen_pe_ph_domain[float](switching_signal, n_sigma, p)\n",
    "        sqrt_pe = sqrt_array[float](pe)\n",
    "        b_grid = getBinomGrid[float](pe, ph, p, parallel = parallel)\n",
    "\n",
    "        if linear_input:\n",
    "            return lambda x, mu, std: c_exact_likelihood_array[float, np.float32_t](\n",
    "                x,  mu, std,\n",
    "                pe, sqrt_pe, ph, b_grid, switching_signal, p, parallel\n",
    "            )\n",
    "        else:\n",
    "            return lambda x, mu, std: c_exact_likelihood_grid[float, np.float32_t](\n",
    "                x,  mu * np.sum(np.where(x > 0, x, 0), axis=-1,keepdims=True), std,\n",
    "                pe, sqrt_pe, ph, b_grid, switching_signal, p, parallel\n",
    "            )\n",
    "\n",
    "    else:\n",
    "        pe, ph = gen_pe_ph_domain[double](switching_signal, n_sigma, p)\n",
    "        sqrt_pe = sqrt_array[double](pe)\n",
    "        b_grid = getBinomGrid[double](pe, ph, p, parallel=parallel)\n",
    "\n",
    "        if linear_input:\n",
    "            return lambda x, mu, std: c_exact_likelihood_array[double, np.float64_t](\n",
    "                x, mu, std,\n",
    "                pe, sqrt_pe, ph, b_grid, switching_signal, p, parallel\n",
    "            )\n",
    "        else:\n",
    "            return lambda x, mu, std: c_exact_likelihood_grid[double, np.float64_t](\n",
    "                x,  mu * np.sum(np.where(x > 0, x, 0), axis=-1,keepdims=True), std,\n",
    "                pe, sqrt_pe, ph, b_grid, switching_signal, p, parallel\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cython serial  : 0.034s ± 0.003s\n",
      "Cython parallel: 0.007s ± 0.001s\n",
      "JAX            : 4.711s ± 0.044s\n",
      "Numba          : 0.006s ± 0.000s\n",
      "TensorFlow     : 0.022s ± 0.002s\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from JAXReimplementation import LikelihoodFunction as LikelihoodFunctionJAX\n",
    "from Numpy_NumbaReimplementation import LikelihoodFunction as LikelihoodFunctionnb\n",
    "from TensorflowImplementation.LikelihoodFunction import LikelihoodRatio\n",
    "\n",
    "# Generate test data\n",
    "np.random.seed(0)\n",
    "B, K = 1000, 200\n",
    "x = np.random.uniform(-3, 10000, size=(B, K)).astype(np.float32)\n",
    "mu = x + np.random.normal(30, 5, size=(B, K)).astype(np.float32)\n",
    "mu = mu / np.sum(mu, axis=1, keepdims=True)\n",
    "std = np.random.uniform(0.05, 1.0, size=K).astype(np.float32)\n",
    "\n",
    "# Build Cython variants\n",
    "fn_serial   = exact_likelihood_generator(0.2, 40.0, 5, parallel=False)\n",
    "fn_parallel = exact_likelihood_generator(0.2, 40.0, 5, parallel=True)\n",
    "\n",
    "# Build JAX variant\n",
    "jax_implement = LikelihoodFunctionJAX.parent_gen(\n",
    "    std, method='Exact', return_ratio=False,\n",
    "    switching_signal=40.0, p_dpe=0.2, n_sigma=5, m=K\n",
    ")\n",
    "\n",
    "# Build Numba variant\n",
    "nb_implement = LikelihoodFunctionnb.parent_gen(\n",
    "    std, method='Exact', return_ratio=False,\n",
    "    switching_signal=40.0, p_dpe=0.2, n_sigma=5, m=K, usenumba=True\n",
    ")\n",
    "\n",
    "# Build TensorFlow variant\n",
    "tf_implement = LikelihoodRatio(\n",
    "    n_pmts=K,\n",
    "    return_ratio=False,\n",
    "    switching_signal=40.0,\n",
    "    n_sigma=5,\n",
    "    sigma_min=0.05,\n",
    "    sigma_max=1,\n",
    "    z=20,\n",
    "    p_dpe=0.2,\n",
    "    nan_safe=False,\n",
    "    nan_safe_value=0.0,\n",
    "    m=K,\n",
    "    mle_estimator=None\n",
    ")\n",
    "tf_implement.std.assign(std)\n",
    "tf_implement.set_call_mode(\"exact\", return_ratio=False)\n",
    "tf_implement.std.assign(std)\n",
    "\n",
    "# Warm‐up\n",
    "_ = fn_serial(x, mu, std)\n",
    "_ = fn_parallel(x, mu, std)\n",
    "_ = jax_implement(x=x, mu=mu).block_until_ready()\n",
    "_ = nb_implement(x=x, mu=mu)\n",
    "_ = tf_implement(mu, x)\n",
    "\n",
    "# Benchmark helper accepting both args and kwargs\n",
    "def bench(fn, *args, repeats=3, **kwargs):\n",
    "    times = []\n",
    "    for _ in range(repeats):\n",
    "        t0 = time.perf_counter()\n",
    "        _ = fn(*args, **kwargs)\n",
    "        t1 = time.perf_counter()\n",
    "        times.append(t1 - t0)\n",
    "    return np.mean(times), np.std(times)\n",
    "def jax_sync(x, mu):\n",
    "    # call the jitted function, then block until the result is ready\n",
    "    return jax_implement(x=x, mu=mu).block_until_ready()\n",
    "\n",
    "# Run benchmarks\n",
    "results = {\n",
    "    'Cython serial':   bench(fn_serial,   x, mu, std),\n",
    "    'Cython parallel': bench(fn_parallel, x, mu, std),\n",
    "    'JAX':             bench(jax_sync, x=x, mu=mu),\n",
    "    'Numba':           bench(nb_implement, x=x, mu=mu),\n",
    "    'TensorFlow':      bench(tf_implement, mu, x),\n",
    "}\n",
    "\n",
    "# Display results\n",
    "for name, (mean_t, std_t) in results.items():\n",
    "    print(f\"{name:15s}: {mean_t:.3f}s ± {std_t:.3f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense Network Comparisons\n",
    "\n",
    "Numba was the fastest overall \n",
    "\n",
    "Tensorflow might be faster on Dense\n",
    "\n",
    "Jax was remarkably dissapointing on my machine"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
